<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>318200</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<div class="cell markdown" data-papermill="{&quot;duration&quot;:2.3581e-2,&quot;end_time&quot;:&quot;2023-07-02T11:32:59.503233&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:32:59.479652&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<p>Hello Fellow Kagglers,</p>
<p>This competition has been challenging to say the least, especially the submission.</p>
<p>After a few weeks I finally got a working training + inference pipeline which is shared through this notebook.</p>
<p>The model consists of a transformer embedding + encoder + decoder.</p>
<p>Inference is performed by starting with an SOS token and predicting one character at a time using the previous prediction.</p>
<p>Feel free to ask for clarafications or comment.</p>
<p>Notebook will be updated periodically.</p>
<p><a href="https://www.kaggle.com/code/markwijkhuizen/aslfr-eda-preprocessing-dataset">Preprocessing Notebook</a></p>
<p><strong>V6</strong></p>
<p>This competition has an inference limit of 5 hours which requires careful allocation of computational resources in the model. Most changes are based on the assymetrical number of encoder/deocder calls during inference.</p>
<p>Inference requires the encoder to encode the input frames and subsequently use that encoding to predict the 1st character by inputting the encoding and SOS (Start of Sentence) token. Next, the encoding, SOS token and 1st predicted token are used to predict the 2nd character. Inference thus requires 1 call to the encoder and multiple calls to the encoder. On average a phrase is 18 characters long, requiring 18+1(SOS token) calls to the decoder. To stay within the 5 hour inference limit the encoder can be computationally heavy, however the decoder should be light.</p>
<p>Some inspiration is taken from the <a href="https://www.kaggle.com/code/hoyso48/1st-place-solution-training">1st place solution - training</a> from the last <a href="https://www.kaggle.com/competitions/asl-signs">Google - Isolated Sign Language Recognition</a> competition.</p>
<ul>
<li>Increased training epochs 30 -&gt; 100</li>
<li>Using all data for training, no validation set</li>
<li>Increased number of decoder blocks 2 -&gt; 3</li>
<li>Increased encoder dimensions 256 -&gt; 384</li>
<li>Halved attention dimension to decrease computational intensity of Multi Head Attention</li>
<li>Added 20% dropout to multi head attention output</li>
<li>Batch size 128 -&gt; 64</li>
<li>Classification layer linear activation for logits in loss function</li>
</ul>
<p><strong>Helpful Tutorials</strong></p>
<p><a href="https://keras.io/examples/nlp/neural_machine_translation_with_transformer/">English-to-Spanish translation with a sequence-to-sequence Transformer</a></p>
<p><a href="https://www.youtube.com/watch?v=KmAISyVvE1Y&amp;list=LL&amp;index=3">Lecture 12.1 Self-attention</a></p>
</div>
<div class="cell code" data-execution_count="1" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:32:59.551155Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:32:59.550390Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:08.728874Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:08.726779Z&quot;}" data-papermill="{&quot;duration&quot;:9.205219,&quot;end_time&quot;:&quot;2023-07-02T11:33:08.731341&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:32:59.526122&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib <span class="im">as</span> mpl</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sn</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow_addons <span class="im">as</span> tfa</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm.notebook <span class="im">import</span> tqdm</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split, GroupShuffleSplit</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> leven <span class="im">import</span> levenshtein</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> glob</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sys</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gc</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sys</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="co"># TQDM Progress Bar With Pandas Apply Function</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>tqdm.pandas()</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Tensorflow Version </span><span class="sc">{</span>tf<span class="sc">.</span>__version__<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Python Version: </span><span class="sc">{</span>sys<span class="sc">.</span>version<span class="sc">}</span><span class="ss">&#39;</span>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: [&#39;/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so&#39;]
caused by: [&#39;/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE&#39;]
  warnings.warn(f&quot;unable to load libtensorflow_io_plugins.so: {e}&quot;)
/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: [&#39;/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so&#39;]
caused by: [&#39;/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE&#39;]
  warnings.warn(f&quot;file system plugins are not loaded: {e}&quot;)
/opt/conda/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Tensorflow Version 2.12.0
Python Version: 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]
</code></pre>
</div>
</div>
<section id="character-2-ordinal-encoding" class="cell markdown" data-papermill="{&quot;duration&quot;:2.2966e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:08.779005&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:08.756039&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Character 2 Ordinal Encoding</h1>
</section>
<div class="cell code" data-execution_count="2" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:08.831302Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:08.829757Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:08.857142Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:08.856198Z&quot;}" data-papermill="{&quot;duration&quot;:5.7156e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:08.859134&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:08.801978&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Read Character to Ordinal Encoding Mapping</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">&#39;/kaggle/input/asl-fingerspelling/character_to_prediction_index.json&#39;</span>) <span class="im">as</span> json_file:</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    CHAR2ORD <span class="op">=</span> json.load(json_file)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Ordinal to Character Mapping</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>ORD2CHAR <span class="op">=</span> {j:i <span class="cf">for</span> i,j <span class="kw">in</span> CHAR2ORD.items()}</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Character to Ordinal Encoding Mapping   </span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>display(pd.Series(CHAR2ORD).to_frame(<span class="st">&#39;Ordinal Encoding&#39;</span>))</span></code></pre></div>
<div class="output display_data">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Ordinal Encoding</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th></th>
      <td>0</td>
    </tr>
    <tr>
      <th>!</th>
      <td>1</td>
    </tr>
    <tr>
      <th>#</th>
      <td>2</td>
    </tr>
    <tr>
      <th>$</th>
      <td>3</td>
    </tr>
    <tr>
      <th>%</th>
      <td>4</td>
    </tr>
    <tr>
      <th>&amp;</th>
      <td>5</td>
    </tr>
    <tr>
      <th>'</th>
      <td>6</td>
    </tr>
    <tr>
      <th>(</th>
      <td>7</td>
    </tr>
    <tr>
      <th>)</th>
      <td>8</td>
    </tr>
    <tr>
      <th>*</th>
      <td>9</td>
    </tr>
    <tr>
      <th>+</th>
      <td>10</td>
    </tr>
    <tr>
      <th>,</th>
      <td>11</td>
    </tr>
    <tr>
      <th>-</th>
      <td>12</td>
    </tr>
    <tr>
      <th>.</th>
      <td>13</td>
    </tr>
    <tr>
      <th>/</th>
      <td>14</td>
    </tr>
    <tr>
      <th>0</th>
      <td>15</td>
    </tr>
    <tr>
      <th>1</th>
      <td>16</td>
    </tr>
    <tr>
      <th>2</th>
      <td>17</td>
    </tr>
    <tr>
      <th>3</th>
      <td>18</td>
    </tr>
    <tr>
      <th>4</th>
      <td>19</td>
    </tr>
    <tr>
      <th>5</th>
      <td>20</td>
    </tr>
    <tr>
      <th>6</th>
      <td>21</td>
    </tr>
    <tr>
      <th>7</th>
      <td>22</td>
    </tr>
    <tr>
      <th>8</th>
      <td>23</td>
    </tr>
    <tr>
      <th>9</th>
      <td>24</td>
    </tr>
    <tr>
      <th>:</th>
      <td>25</td>
    </tr>
    <tr>
      <th>;</th>
      <td>26</td>
    </tr>
    <tr>
      <th>=</th>
      <td>27</td>
    </tr>
    <tr>
      <th>?</th>
      <td>28</td>
    </tr>
    <tr>
      <th>@</th>
      <td>29</td>
    </tr>
    <tr>
      <th>[</th>
      <td>30</td>
    </tr>
    <tr>
      <th>_</th>
      <td>31</td>
    </tr>
    <tr>
      <th>a</th>
      <td>32</td>
    </tr>
    <tr>
      <th>b</th>
      <td>33</td>
    </tr>
    <tr>
      <th>c</th>
      <td>34</td>
    </tr>
    <tr>
      <th>d</th>
      <td>35</td>
    </tr>
    <tr>
      <th>e</th>
      <td>36</td>
    </tr>
    <tr>
      <th>f</th>
      <td>37</td>
    </tr>
    <tr>
      <th>g</th>
      <td>38</td>
    </tr>
    <tr>
      <th>h</th>
      <td>39</td>
    </tr>
    <tr>
      <th>i</th>
      <td>40</td>
    </tr>
    <tr>
      <th>j</th>
      <td>41</td>
    </tr>
    <tr>
      <th>k</th>
      <td>42</td>
    </tr>
    <tr>
      <th>l</th>
      <td>43</td>
    </tr>
    <tr>
      <th>m</th>
      <td>44</td>
    </tr>
    <tr>
      <th>n</th>
      <td>45</td>
    </tr>
    <tr>
      <th>o</th>
      <td>46</td>
    </tr>
    <tr>
      <th>p</th>
      <td>47</td>
    </tr>
    <tr>
      <th>q</th>
      <td>48</td>
    </tr>
    <tr>
      <th>r</th>
      <td>49</td>
    </tr>
    <tr>
      <th>s</th>
      <td>50</td>
    </tr>
    <tr>
      <th>t</th>
      <td>51</td>
    </tr>
    <tr>
      <th>u</th>
      <td>52</td>
    </tr>
    <tr>
      <th>v</th>
      <td>53</td>
    </tr>
    <tr>
      <th>w</th>
      <td>54</td>
    </tr>
    <tr>
      <th>x</th>
      <td>55</td>
    </tr>
    <tr>
      <th>y</th>
      <td>56</td>
    </tr>
    <tr>
      <th>z</th>
      <td>57</td>
    </tr>
    <tr>
      <th>~</th>
      <td>58</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<section id="global-config" class="cell markdown" data-papermill="{&quot;duration&quot;:2.2903e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:08.905507&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:08.882604&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Global Config</h1>
</section>
<div class="cell code" data-execution_count="3" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:08.953600Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:08.953227Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:08.961143Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:08.960094Z&quot;}" data-papermill="{&quot;duration&quot;:3.4637e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:08.963209&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:08.928572&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># If Notebook Is Run By Committing or In Interactive Mode For Development</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>IS_INTERACTIVE <span class="op">=</span> os.environ[<span class="st">&#39;KAGGLE_KERNEL_RUN_TYPE&#39;</span>] <span class="op">==</span> <span class="st">&#39;Interactive&#39;</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Verbose Setting during training</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>VERBOSE <span class="op">=</span> <span class="dv">1</span> <span class="cf">if</span> IS_INTERACTIVE <span class="cf">else</span> <span class="dv">2</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Global Random Seed</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>SEED <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of Frames to resize recording to</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>N_TARGET_FRAMES <span class="op">=</span> <span class="dv">128</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Global debug flag, takes subset of train</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>DEBUG <span class="op">=</span> <span class="va">False</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of Unique Characters To Predict + Pad Token + SOS Token + EOS Token</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>N_UNIQUE_CHARACTERS0 <span class="op">=</span> <span class="bu">len</span>(CHAR2ORD)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>N_UNIQUE_CHARACTERS <span class="op">=</span> <span class="bu">len</span>(CHAR2ORD) <span class="op">+</span> <span class="dv">1</span> <span class="op">+</span> <span class="dv">1</span> <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>PAD_TOKEN <span class="op">=</span> <span class="bu">len</span>(CHAR2ORD) <span class="co"># Padding</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>SOS_TOKEN <span class="op">=</span> <span class="bu">len</span>(CHAR2ORD) <span class="op">+</span> <span class="dv">1</span> <span class="co"># Start Of Sentence</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>EOS_TOKEN <span class="op">=</span> <span class="bu">len</span>(CHAR2ORD) <span class="op">+</span> <span class="dv">2</span> <span class="co"># End Of Sentence</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Whether to use 10% of data for validation</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>USE_VAL <span class="op">=</span> <span class="va">False</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Batch Size</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of Epochs to Train for</span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>N_EPOCHS <span class="op">=</span> <span class="dv">2</span> <span class="cf">if</span> IS_INTERACTIVE <span class="cf">else</span> <span class="dv">100</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of Warmup Epochs in Learning Rate Scheduler</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>N_WARMUP_EPOCHS <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Maximum Learning Rate</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>LR_MAX <span class="op">=</span> <span class="fl">1e-3</span></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Weight Decay Ratio as Ratio of Learning Rate</span></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>WD_RATIO <span class="op">=</span> <span class="fl">0.05</span></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Length of Phrase + EOS Token</span></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>MAX_PHRASE_LENGTH <span class="op">=</span> <span class="dv">31</span> <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Whether to Train The model</span></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>TRAIN_MODEL <span class="op">=</span> <span class="va">True</span></span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Whether to Load Pretrained Weights</span></span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>LOAD_WEIGHTS <span class="op">=</span> <span class="va">False</span></span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Learning Rate Warmup Method [log,exp]</span></span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>WARMUP_METHOD <span class="op">=</span> <span class="st">&#39;exp&#39;</span></span></code></pre></div>
</div>
<section id="plot-config" class="cell markdown" data-papermill="{&quot;duration&quot;:2.3356e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:09.010520&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:08.987164&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Plot Config</h1>
</section>
<div class="cell code" data-execution_count="4" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:09.059675Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:09.058685Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:09.066023Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:09.065070Z&quot;}" data-papermill="{&quot;duration&quot;:3.4116e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:09.068311&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:09.034195&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># MatplotLib Global Settings</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>mpl.rcParams.update(mpl.rcParamsDefault)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>mpl.rcParams[<span class="st">&#39;xtick.labelsize&#39;</span>] <span class="op">=</span> <span class="dv">16</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>mpl.rcParams[<span class="st">&#39;ytick.labelsize&#39;</span>] <span class="op">=</span> <span class="dv">16</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>mpl.rcParams[<span class="st">&#39;axes.labelsize&#39;</span>] <span class="op">=</span> <span class="dv">18</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>mpl.rcParams[<span class="st">&#39;axes.titlesize&#39;</span>] <span class="op">=</span> <span class="dv">24</span></span></code></pre></div>
</div>
<section id="train" class="cell markdown" data-papermill="{&quot;duration&quot;:2.3106e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:09.114637&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:09.091531&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Train</h1>
</section>
<div class="cell code" data-execution_count="5" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:09.163663Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:09.163310Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:09.371641Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:09.370529Z&quot;}" data-papermill="{&quot;duration&quot;:0.236261,&quot;end_time&quot;:&quot;2023-07-02T11:33:09.374134&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:09.137873&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Read Train DataFrame</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> DEBUG:</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    train <span class="op">=</span> pd.read_csv(<span class="st">&#39;/kaggle/input/asl-fingerspelling/train.csv&#39;</span>).head(<span class="dv">5000</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    train <span class="op">=</span> pd.read_csv(<span class="st">&#39;/kaggle/input/asl-fingerspelling/train.csv&#39;</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Set Train Indexed By sqeuence_id</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>train_sequence_id <span class="op">=</span> train.set_index(<span class="st">&#39;sequence_id&#39;</span>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Number Of Train Samples</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>N_SAMPLES <span class="op">=</span> <span class="bu">len</span>(train)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;N_SAMPLES: </span><span class="sc">{</span>N_SAMPLES<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>display(train.info())</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>display(train.head())</span></code></pre></div>
<div class="output stream stdout">
<pre><code>N_SAMPLES: 67208
&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 67208 entries, 0 to 67207
Data columns (total 5 columns):
 #   Column          Non-Null Count  Dtype 
---  ------          --------------  ----- 
 0   path            67208 non-null  object
 1   file_id         67208 non-null  int64 
 2   sequence_id     67208 non-null  int64 
 3   participant_id  67208 non-null  int64 
 4   phrase          67208 non-null  object
dtypes: int64(3), object(2)
memory usage: 2.6+ MB
</code></pre>
</div>
<div class="output display_data">
<pre><code>None</code></pre>
</div>
<div class="output display_data">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>path</th>
      <th>file_id</th>
      <th>sequence_id</th>
      <th>participant_id</th>
      <th>phrase</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>train_landmarks/5414471.parquet</td>
      <td>5414471</td>
      <td>1816796431</td>
      <td>217</td>
      <td>3 creekhouse</td>
    </tr>
    <tr>
      <th>1</th>
      <td>train_landmarks/5414471.parquet</td>
      <td>5414471</td>
      <td>1816825349</td>
      <td>107</td>
      <td>scales/kuhaylah</td>
    </tr>
    <tr>
      <th>2</th>
      <td>train_landmarks/5414471.parquet</td>
      <td>5414471</td>
      <td>1816909464</td>
      <td>1</td>
      <td>1383 william lanier</td>
    </tr>
    <tr>
      <th>3</th>
      <td>train_landmarks/5414471.parquet</td>
      <td>5414471</td>
      <td>1816967051</td>
      <td>63</td>
      <td>988 franklin lane</td>
    </tr>
    <tr>
      <th>4</th>
      <td>train_landmarks/5414471.parquet</td>
      <td>5414471</td>
      <td>1817123330</td>
      <td>89</td>
      <td>6920 northeast 661st road</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<section id="file-path" class="cell markdown" data-papermill="{&quot;duration&quot;:2.3663e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:09.422133&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:09.398470&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>File Path</h1>
</section>
<div class="cell code" data-execution_count="6" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:09.472032Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:09.471235Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:09.502682Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:09.501766Z&quot;}" data-papermill="{&quot;duration&quot;:5.8827e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:09.504965&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:09.446138&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get complete file path to file</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_file_path(path):</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="ss">f&#39;/kaggle/input/asl-fingerspelling/</span><span class="sc">{</span>path<span class="sc">}</span><span class="ss">&#39;</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&#39;file_path&#39;</span>] <span class="op">=</span> train[<span class="st">&#39;path&#39;</span>].<span class="bu">apply</span>(get_file_path)</span></code></pre></div>
</div>
<section id="example-file-paths" class="cell markdown" data-papermill="{&quot;duration&quot;:2.3756e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:09.552626&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:09.528870&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Example File Paths</h1>
</section>
<div class="cell code" data-execution_count="7" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:09.603421Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:09.602463Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:09.612400Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:09.611306Z&quot;}" data-papermill="{&quot;duration&quot;:3.8118e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:09.614891&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:09.576773&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Unique Parquet Files</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>INFERENCE_FILE_PATHS <span class="op">=</span> pd.Series(</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>        glob.glob(<span class="st">&#39;/kaggle/input/aslfr-preprocessing-dataset/train_landmark_subsets/*&#39;</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Found </span><span class="sc">{</span><span class="bu">len</span>(INFERENCE_FILE_PATHS)<span class="sc">}</span><span class="ss"> Inference Pickle Files&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Found 10 Inference Pickle Files
</code></pre>
</div>
</div>
<section id="load-xy" class="cell markdown" data-papermill="{&quot;duration&quot;:2.3663e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:09.662914&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:09.639251&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Load X/y</h1>
</section>
<div class="cell code" data-execution_count="8" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:09.711804Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:09.711463Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:47.300790Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:47.299760Z&quot;}" data-papermill="{&quot;duration&quot;:37.639487,&quot;end_time&quot;:&quot;2023-07-02T11:33:47.326164&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:09.686677&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train/Validation</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> USE_VAL:</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># TRAIN</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    X_train <span class="op">=</span> np.load(<span class="st">&#39;/kaggle/input/aslfr-preprocessing-dataset/X_train.npy&#39;</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    y_train <span class="op">=</span> np.load(<span class="st">&#39;/kaggle/input/aslfr-preprocessing-dataset/y_train.npy&#39;</span>)[:,:MAX_PHRASE_LENGTH]</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    N_TRAIN_SAMPLES <span class="op">=</span> <span class="bu">len</span>(X_train)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># VAL</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    X_val <span class="op">=</span> np.load(<span class="st">&#39;/kaggle/input/aslfr-preprocessing-dataset/X_val.npy&#39;</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    y_val <span class="op">=</span> np.load(<span class="st">&#39;/kaggle/input/aslfr-preprocessing-dataset/y_val.npy&#39;</span>)[:,:MAX_PHRASE_LENGTH]</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    N_VAL_SAMPLES <span class="op">=</span> <span class="bu">len</span>(X_val)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Shapes</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&#39;X_train shape: </span><span class="sc">{</span>X_train<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, X_val shape: </span><span class="sc">{</span>X_val<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Train On All Data</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># TRAIN</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>    X_train <span class="op">=</span> np.load(<span class="st">&#39;/kaggle/input/aslfr-preprocessing-dataset/X.npy&#39;</span>)</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>    y_train <span class="op">=</span> np.load(<span class="st">&#39;/kaggle/input/aslfr-preprocessing-dataset/y.npy&#39;</span>)[:,:MAX_PHRASE_LENGTH]</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>    N_TRAIN_SAMPLES <span class="op">=</span> <span class="bu">len</span>(X_train)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&#39;X_train shape: </span><span class="sc">{</span>X_train<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>X_train shape: (61955, 128, 164)
</code></pre>
</div>
</div>
<section id="example-batch" class="cell markdown" data-papermill="{&quot;duration&quot;:2.373e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:47.374154&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:47.350424&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Example Batch</h1>
</section>
<div class="cell code" data-execution_count="9" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:47.423548Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:47.423199Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:47.489213Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:47.488214Z&quot;}" data-papermill="{&quot;duration&quot;:9.3503e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:47.491607&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:47.398104&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example Batch For Debugging</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>N_EXAMPLE_BATCH_SAMPLES <span class="op">=</span> <span class="dv">1024</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>N_EXAMPLE_BATCH_SAMPLES_SMALL <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Example Batch</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>X_batch <span class="op">=</span> {</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;frames&#39;</span>: np.copy(X_train[:N_EXAMPLE_BATCH_SAMPLES]),</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;phrase&#39;</span>: np.copy(y_train[:N_EXAMPLE_BATCH_SAMPLES]),</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="co">#     &#39;phrase_type&#39;: np.copy(y_phrase_type_train[:N_EXAMPLE_BATCH_SAMPLES]),</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>y_batch <span class="op">=</span> np.copy(y_train[:N_EXAMPLE_BATCH_SAMPLES])</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Small Example Batch</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>X_batch_small <span class="op">=</span> {</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;frames&#39;</span>: np.copy(X_train[:N_EXAMPLE_BATCH_SAMPLES_SMALL]),</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;phrase&#39;</span>: np.copy(y_train[:N_EXAMPLE_BATCH_SAMPLES_SMALL]),</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a><span class="co">#     &#39;phrase_type&#39;: np.copy(y_phrase_type_train[:N_EXAMPLE_BATCH_SAMPLES_SMALL]),</span></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>y_batch_small <span class="op">=</span> np.copy(y_train[:N_EXAMPLE_BATCH_SAMPLES_SMALL])</span></code></pre></div>
</div>
<section id="example-parquet" class="cell markdown" data-papermill="{&quot;duration&quot;:2.3639e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:47.539567&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:47.515928&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Example Parquet</h1>
</section>
<div class="cell code" data-execution_count="10" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:47.588978Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:47.587412Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:49.069106Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:49.067910Z&quot;}" data-papermill="{&quot;duration&quot;:1.512276,&quot;end_time&quot;:&quot;2023-07-02T11:33:49.075196&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:47.562920&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Read First Parquet File</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="co"># example_parquet_df = pd.read_parquet(train[&#39;file_path&#39;][0])</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>example_parquet_df <span class="op">=</span> pd.read_parquet(INFERENCE_FILE_PATHS[<span class="dv">0</span>])</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Each parquet file contains 1000 recordings</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;# Unique Recording: </span><span class="sc">{</span>example_parquet_df<span class="sc">.</span>index<span class="sc">.</span>nunique()<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Display DataFrame layout</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>display(example_parquet_df.head())</span></code></pre></div>
<div class="output stream stdout">
<pre><code># Unique Recording: 1000
</code></pre>
</div>
<div class="output display_data">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x_left_hand_0</th>
      <th>x_left_hand_1</th>
      <th>x_left_hand_2</th>
      <th>x_left_hand_3</th>
      <th>x_left_hand_4</th>
      <th>x_left_hand_5</th>
      <th>x_left_hand_6</th>
      <th>x_left_hand_7</th>
      <th>x_left_hand_8</th>
      <th>x_left_hand_9</th>
      <th>...</th>
      <th>y_face_314</th>
      <th>y_face_317</th>
      <th>y_face_318</th>
      <th>y_face_321</th>
      <th>y_face_324</th>
      <th>y_face_375</th>
      <th>y_face_402</th>
      <th>y_face_405</th>
      <th>y_face_409</th>
      <th>y_face_415</th>
    </tr>
    <tr>
      <th>sequence_id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1816796431</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>0.551424</td>
      <td>0.538415</td>
      <td>0.539000</td>
      <td>0.546458</td>
      <td>0.539715</td>
      <td>0.543958</td>
      <td>0.538425</td>
      <td>0.549351</td>
      <td>0.538230</td>
      <td>0.540015</td>
    </tr>
    <tr>
      <th>1816796431</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>0.550706</td>
      <td>0.538216</td>
      <td>0.538723</td>
      <td>0.545990</td>
      <td>0.539296</td>
      <td>0.543357</td>
      <td>0.538225</td>
      <td>0.548827</td>
      <td>0.537376</td>
      <td>0.539256</td>
    </tr>
    <tr>
      <th>1816796431</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>0.550613</td>
      <td>0.537836</td>
      <td>0.538564</td>
      <td>0.545949</td>
      <td>0.539212</td>
      <td>0.543279</td>
      <td>0.537961</td>
      <td>0.548796</td>
      <td>0.537360</td>
      <td>0.539332</td>
    </tr>
    <tr>
      <th>1816796431</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>0.549740</td>
      <td>0.536994</td>
      <td>0.538449</td>
      <td>0.545622</td>
      <td>0.539666</td>
      <td>0.543694</td>
      <td>0.537328</td>
      <td>0.548015</td>
      <td>0.538301</td>
      <td>0.539954</td>
    </tr>
    <tr>
      <th>1816796431</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>0.550614</td>
      <td>0.538677</td>
      <td>0.540376</td>
      <td>0.547104</td>
      <td>0.541524</td>
      <td>0.545222</td>
      <td>0.539203</td>
      <td>0.549211</td>
      <td>0.539734</td>
      <td>0.541707</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 164 columns</p>
</div>
</div>
</div>
<section id="landmark-indices" class="cell markdown" data-papermill="{&quot;duration&quot;:3.9462e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:49.150383&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:49.110921&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Landmark Indices</h1>
</section>
<div class="cell code" data-execution_count="11" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:49.220746Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:49.220313Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:49.232562Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:49.231640Z&quot;}" data-papermill="{&quot;duration&quot;:5.1023e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:49.235748&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:49.184725&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get indices in original dataframe</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_idxs(df, words_pos, words_neg<span class="op">=</span>[], ret_names<span class="op">=</span><span class="va">True</span>, idxs_pos<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    idxs <span class="op">=</span> []</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    names <span class="op">=</span> []</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> w <span class="kw">in</span> words_pos:</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> col_idx, col <span class="kw">in</span> <span class="bu">enumerate</span>(example_parquet_df.columns):</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Exclude Non Landmark Columns</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> col <span class="kw">in</span> [<span class="st">&#39;frame&#39;</span>]:</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>                <span class="cf">continue</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>            col_idx <span class="op">=</span> <span class="bu">int</span>(col.split(<span class="st">&#39;_&#39;</span>)[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Check if column name contains all words</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> (w <span class="kw">in</span> col) <span class="kw">and</span> (idxs_pos <span class="kw">is</span> <span class="va">None</span> <span class="kw">or</span> col_idx <span class="kw">in</span> idxs_pos) <span class="kw">and</span> <span class="bu">all</span>([w <span class="kw">not</span> <span class="kw">in</span> col <span class="cf">for</span> w <span class="kw">in</span> words_neg]):</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>                idxs.append(col_idx)</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>                names.append(col)</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert to Numpy arrays</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>    idxs <span class="op">=</span> np.array(idxs)</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>    names <span class="op">=</span> np.array(names)</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Returns either both column indices and names</span></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> ret_names:</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> idxs, names</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Or only columns indices</span></span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> idxs</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="12" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:49.306607Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:49.306194Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:49.322144Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:49.321310Z&quot;}" data-papermill="{&quot;duration&quot;:5.3701e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:49.324986&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:49.271285&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Lips Landmark Face Ids</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>LIPS_LANDMARK_IDXS <span class="op">=</span> np.array([</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>        <span class="dv">61</span>, <span class="dv">185</span>, <span class="dv">40</span>, <span class="dv">39</span>, <span class="dv">37</span>, <span class="dv">0</span>, <span class="dv">267</span>, <span class="dv">269</span>, <span class="dv">270</span>, <span class="dv">409</span>,</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>        <span class="dv">291</span>, <span class="dv">146</span>, <span class="dv">91</span>, <span class="dv">181</span>, <span class="dv">84</span>, <span class="dv">17</span>, <span class="dv">314</span>, <span class="dv">405</span>, <span class="dv">321</span>, <span class="dv">375</span>,</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>        <span class="dv">78</span>, <span class="dv">191</span>, <span class="dv">80</span>, <span class="dv">81</span>, <span class="dv">82</span>, <span class="dv">13</span>, <span class="dv">312</span>, <span class="dv">311</span>, <span class="dv">310</span>, <span class="dv">415</span>,</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>        <span class="dv">95</span>, <span class="dv">88</span>, <span class="dv">178</span>, <span class="dv">87</span>, <span class="dv">14</span>, <span class="dv">317</span>, <span class="dv">402</span>, <span class="dv">318</span>, <span class="dv">324</span>, <span class="dv">308</span>,</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Landmark Indices for Left/Right hand without z axis in raw data</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>LEFT_HAND_IDXS0, LEFT_HAND_NAMES0 <span class="op">=</span> get_idxs(example_parquet_df, [<span class="st">&#39;left_hand&#39;</span>], [<span class="st">&#39;z&#39;</span>])</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>RIGHT_HAND_IDXS0, RIGHT_HAND_NAMES0 <span class="op">=</span> get_idxs(example_parquet_df, [<span class="st">&#39;right_hand&#39;</span>], [<span class="st">&#39;z&#39;</span>])</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>LIPS_IDXS0, LIPS_NAMES0 <span class="op">=</span> get_idxs(example_parquet_df, [<span class="st">&#39;face&#39;</span>], [<span class="st">&#39;z&#39;</span>], idxs_pos<span class="op">=</span>LIPS_LANDMARK_IDXS)</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>COLUMNS0 <span class="op">=</span> np.concatenate((LEFT_HAND_NAMES0, RIGHT_HAND_NAMES0, LIPS_NAMES0))</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>N_COLS0 <span class="op">=</span> <span class="bu">len</span>(COLUMNS0)</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Only X/Y axes are used</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>N_DIMS0 <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;N_COLS0: </span><span class="sc">{</span>N_COLS0<span class="sc">}</span><span class="ss">&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>N_COLS0: 164
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="13" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:49.394155Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:49.393673Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:49.405067Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:49.404193Z&quot;}" data-papermill="{&quot;duration&quot;:5.0026e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:49.408684&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:49.358658&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Landmark Indices in subset of dataframe with only COLUMNS selected</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>LEFT_HAND_IDXS <span class="op">=</span> np.argwhere(np.isin(COLUMNS0, LEFT_HAND_NAMES0)).squeeze()</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>RIGHT_HAND_IDXS <span class="op">=</span> np.argwhere(np.isin(COLUMNS0, RIGHT_HAND_NAMES0)).squeeze()</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>LIPS_IDXS <span class="op">=</span> np.argwhere(np.isin(COLUMNS0, LIPS_NAMES0)).squeeze()</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>HAND_IDXS <span class="op">=</span> np.concatenate((LEFT_HAND_IDXS, RIGHT_HAND_IDXS), axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>N_COLS <span class="op">=</span> N_COLS0</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Only X/Y axes are used</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>N_DIMS <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;N_COLS: </span><span class="sc">{</span>N_COLS<span class="sc">}</span><span class="ss">&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>N_COLS: 164
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="14" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:49.478814Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:49.478411Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:49.485728Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:49.484813Z&quot;}" data-papermill="{&quot;duration&quot;:4.5648e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:49.488024&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:49.442376&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Indices in processed data by axes with only dominant hand</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>HAND_X_IDXS <span class="op">=</span> np.array(</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>        [idx <span class="cf">for</span> idx, name <span class="kw">in</span> <span class="bu">enumerate</span>(LEFT_HAND_NAMES0) <span class="cf">if</span> <span class="st">&#39;x&#39;</span> <span class="kw">in</span> name]</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    ).squeeze()</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>HAND_Y_IDXS <span class="op">=</span> np.array(</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>        [idx <span class="cf">for</span> idx, name <span class="kw">in</span> <span class="bu">enumerate</span>(LEFT_HAND_NAMES0) <span class="cf">if</span> <span class="st">&#39;y&#39;</span> <span class="kw">in</span> name]</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>    ).squeeze()</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Names in processed data by axes</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>HAND_X_NAMES <span class="op">=</span> LEFT_HAND_NAMES0[HAND_X_IDXS]</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>HAND_Y_NAMES <span class="op">=</span> LEFT_HAND_NAMES0[HAND_Y_IDXS]</span></code></pre></div>
</div>
<section id="meanstd-loading" class="cell markdown" data-papermill="{&quot;duration&quot;:3.7446e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:49.563172&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:49.525726&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Mean/STD Loading</h1>
</section>
<div class="cell code" data-execution_count="15" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:49.634678Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:49.634269Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:49.646152Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:49.645268Z&quot;}" data-papermill="{&quot;duration&quot;:5.1188e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:49.648816&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:49.597628&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Mean/Standard Deviations of data used for normalizing</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>MEANS <span class="op">=</span> np.load(<span class="st">&#39;/kaggle/input/aslfr-preprocessing-dataset/MEANS.npy&#39;</span>).reshape(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>STDS <span class="op">=</span> np.load(<span class="st">&#39;/kaggle/input/aslfr-preprocessing-dataset/STDS.npy&#39;</span>).reshape(<span class="op">-</span><span class="dv">1</span>)</span></code></pre></div>
</div>
<section id="tensorflow-preprocessing-layer" class="cell markdown" data-papermill="{&quot;duration&quot;:3.3837e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:49.717492&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:49.683655&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Tensorflow Preprocessing Layer</h1>
</section>
<div class="cell code" data-execution_count="16" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:49.787674Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:49.787278Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:52.818121Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:52.817063Z&quot;}" data-papermill="{&quot;duration&quot;:3.068754,&quot;end_time&quot;:&quot;2023-07-02T11:33:52.820674&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:49.751920&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb25"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co">&quot;&quot;&quot;</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="co">    Tensorflow layer to process data in TFLite</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Data needs to be processed in the model itself, so we can not use Python</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="co">&quot;&quot;&quot;</span> </span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> PreprocessLayer(tf.keras.layers.Layer):</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(PreprocessLayer, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.normalisation_correction <span class="op">=</span> tf.constant(</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># Add 0.50 to x coordinates of left hand (original right hand) and substract 0.50 of right hand (original left hand)</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>                     [<span class="fl">0.50</span> <span class="cf">if</span> <span class="st">&#39;x&#39;</span> <span class="kw">in</span> name <span class="cf">else</span> <span class="fl">0.00</span> <span class="cf">for</span> name <span class="kw">in</span> LEFT_HAND_NAMES0],</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>                dtype<span class="op">=</span>tf.float32,</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">@tf.function</span>(</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>        input_signature<span class="op">=</span>(tf.TensorSpec(shape<span class="op">=</span>[<span class="va">None</span>,N_COLS0], dtype<span class="op">=</span>tf.float32),),</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, data0, resize<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fill NaN Values With 0</span></span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>        data <span class="op">=</span> tf.where(tf.math.is_nan(data0), <span class="fl">0.0</span>, data0)</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Hacky</span></span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a>        data <span class="op">=</span> data[<span class="va">None</span>]</span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Empty Hand Frame Filtering</span></span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>        hands <span class="op">=</span> tf.<span class="bu">slice</span>(data, [<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>], [<span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>, <span class="dv">84</span>])</span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a>        hands <span class="op">=</span> tf.<span class="bu">abs</span>(hands)</span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a>        mask <span class="op">=</span> tf.reduce_sum(hands, axis<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a>        mask <span class="op">=</span> tf.not_equal(mask, <span class="dv">0</span>)</span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a>        data <span class="op">=</span> data[mask][<span class="va">None</span>]</span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Pad Zeros</span></span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a>        N_FRAMES <span class="op">=</span> <span class="bu">len</span>(data[<span class="dv">0</span>])</span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> N_FRAMES <span class="op">&lt;</span> N_TARGET_FRAMES:</span>
<span id="cb25-34"><a href="#cb25-34" aria-hidden="true" tabindex="-1"></a>            data <span class="op">=</span> tf.concat((</span>
<span id="cb25-35"><a href="#cb25-35" aria-hidden="true" tabindex="-1"></a>                data,</span>
<span id="cb25-36"><a href="#cb25-36" aria-hidden="true" tabindex="-1"></a>                tf.zeros([<span class="dv">1</span>,N_TARGET_FRAMES<span class="op">-</span>N_FRAMES,N_COLS], dtype<span class="op">=</span>tf.float32)</span>
<span id="cb25-37"><a href="#cb25-37" aria-hidden="true" tabindex="-1"></a>            ), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb25-38"><a href="#cb25-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Downsample</span></span>
<span id="cb25-39"><a href="#cb25-39" aria-hidden="true" tabindex="-1"></a>        data <span class="op">=</span> tf.image.resize(</span>
<span id="cb25-40"><a href="#cb25-40" aria-hidden="true" tabindex="-1"></a>            data,</span>
<span id="cb25-41"><a href="#cb25-41" aria-hidden="true" tabindex="-1"></a>            [<span class="dv">1</span>, N_TARGET_FRAMES],</span>
<span id="cb25-42"><a href="#cb25-42" aria-hidden="true" tabindex="-1"></a>            method<span class="op">=</span>tf.image.ResizeMethod.BILINEAR,</span>
<span id="cb25-43"><a href="#cb25-43" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb25-44"><a href="#cb25-44" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb25-45"><a href="#cb25-45" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Squeeze Batch Dimension</span></span>
<span id="cb25-46"><a href="#cb25-46" aria-hidden="true" tabindex="-1"></a>        data <span class="op">=</span> tf.squeeze(data, axis<span class="op">=</span>[<span class="dv">0</span>])</span>
<span id="cb25-47"><a href="#cb25-47" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb25-48"><a href="#cb25-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> data</span>
<span id="cb25-49"><a href="#cb25-49" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-50"><a href="#cb25-50" aria-hidden="true" tabindex="-1"></a>preprocess_layer <span class="op">=</span> PreprocessLayer()</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="17" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:52.875173Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:52.874779Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:52.882683Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:52.881754Z&quot;}" data-papermill="{&quot;duration&quot;:3.8316e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:52.885017&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:52.846701&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb26"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Function To Test Preprocessing Layer</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test_preprocess_layer():</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>    demo_sequence_id <span class="op">=</span> example_parquet_df.index.unique()[<span class="dv">15</span>]</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>    demo_raw_data <span class="op">=</span> example_parquet_df.loc[demo_sequence_id, COLUMNS0]</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> preprocess_layer(demo_raw_data)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&#39;demo_raw_data shape: </span><span class="sc">{</span>demo_raw_data<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&#39;data shape: </span><span class="sc">{</span>data<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> data</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> IS_INTERACTIVE:</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> test_preprocess_layer()</span></code></pre></div>
</div>
<section id="train-dataset" class="cell markdown" data-papermill="{&quot;duration&quot;:2.3965e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:52.934821&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:52.910856&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Train Dataset</h1>
</section>
<div class="cell code" data-execution_count="18" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:52.984919Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:52.984565Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:52.990291Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:52.989395Z&quot;}" data-papermill="{&quot;duration&quot;:3.3186e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:52.992213&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:52.959027&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb27"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train Dataset Iterator</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_train_dataset(X, y, batch_size<span class="op">=</span>BATCH_SIZE):</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>    sample_idxs <span class="op">=</span> np.arange(<span class="bu">len</span>(X))</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get random indices</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>        random_sample_idxs <span class="op">=</span> np.random.choice(sample_idxs, batch_size)</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>        inputs <span class="op">=</span> {</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;frames&#39;</span>: X[random_sample_idxs],</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;phrase&#39;</span>: y[random_sample_idxs],</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> y[random_sample_idxs]</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">yield</span> inputs, outputs</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="19" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:53.045648Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:53.044715Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:53.049868Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:53.048953Z&quot;}" data-papermill="{&quot;duration&quot;:3.572e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:53.051965&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:53.016245&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb28"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train Dataset</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> get_train_dataset(X_train, y_train)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="20" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:53.104021Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:53.102989Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:53.109721Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:53.108280Z&quot;}" data-papermill="{&quot;duration&quot;:3.4525e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:53.111793&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:53.077268&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb29"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Training Steps Per Epoch</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>TRAIN_STEPS_PER_EPOCH <span class="op">=</span> math.ceil(N_TRAIN_SAMPLES <span class="op">/</span> BATCH_SIZE)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;TRAIN_STEPS_PER_EPOCH: </span><span class="sc">{</span>TRAIN_STEPS_PER_EPOCH<span class="sc">}</span><span class="ss">&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>TRAIN_STEPS_PER_EPOCH: 969
</code></pre>
</div>
</div>
<section id="validation-dataset" class="cell markdown" data-papermill="{&quot;duration&quot;:2.478e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:53.161179&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:53.136399&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Validation Dataset</h1>
</section>
<div class="cell code" data-execution_count="21" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:53.212522Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:53.212173Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:53.218203Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:53.217272Z&quot;}" data-papermill="{&quot;duration&quot;:3.44e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:53.220231&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:53.185831&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb31"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Validation Set</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_val_dataset(X, y, batch_size<span class="op">=</span>BATCH_SIZE):</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>    offsets <span class="op">=</span> np.arange(<span class="dv">0</span>, <span class="bu">len</span>(X), batch_size)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Iterate over whole validation set</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> offset <span class="kw">in</span> offsets:</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>            inputs <span class="op">=</span> {</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>                <span class="st">&#39;frames&#39;</span>: X[offset:offset<span class="op">+</span>batch_size],</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>                <span class="st">&#39;phrase&#39;</span>: y[offset:offset<span class="op">+</span>batch_size],</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> y[offset:offset<span class="op">+</span>batch_size]</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>            <span class="cf">yield</span> inputs, outputs</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="22" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:53.270371Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:53.269581Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:53.274319Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:53.273464Z&quot;}" data-papermill="{&quot;duration&quot;:3.1785e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:53.276318&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:53.244533&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb32"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Validation Dataset</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> USE_VAL:</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>    val_dataset <span class="op">=</span> get_val_dataset(X_val, y_val)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="23" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:53.326652Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:53.325736Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:53.330661Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:53.329815Z&quot;}" data-papermill="{&quot;duration&quot;:3.2228e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:53.332610&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:53.300382&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb33"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> USE_VAL:</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>    N_VAL_STEPS_PER_EPOCH <span class="op">=</span> math.ceil(N_VAL_SAMPLES <span class="op">/</span> BATCH_SIZE)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&#39;N_VAL_STEPS_PER_EPOCH: </span><span class="sc">{</span>N_VAL_STEPS_PER_EPOCH<span class="sc">}</span><span class="ss">&#39;</span>)</span></code></pre></div>
</div>
<section id="model-config" class="cell markdown" data-papermill="{&quot;duration&quot;:2.43e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:53.381866&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:53.357566&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Model Config</h1>
</section>
<div class="cell code" data-execution_count="24" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:53.435100Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:53.434103Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:53.441297Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:53.440387Z&quot;}" data-papermill="{&quot;duration&quot;:3.6845e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:53.443416&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:53.406571&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb34"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Epsilon value for layer normalisation</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>LAYER_NORM_EPS <span class="op">=</span> <span class="fl">1e-6</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="co"># final embedding and transformer embedding size</span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>UNITS_ENCODER <span class="op">=</span> <span class="dv">384</span></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>UNITS_DECODER <span class="op">=</span> <span class="dv">256</span></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Transformer</span></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>NUM_BLOCKS_ENCODER <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>NUM_BLOCKS_DECODER <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>NUM_HEADS <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>MLP_RATIO <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Dropout</span></span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a>EMBEDDING_DROPOUT <span class="op">=</span> <span class="fl">0.00</span></span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a>MLP_DROPOUT_RATIO <span class="op">=</span> <span class="fl">0.30</span></span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a>MHA_DROPOUT_RATIO <span class="op">=</span> <span class="fl">0.20</span></span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a>CLASSIFIER_DROPOUT_RATIO <span class="op">=</span> <span class="fl">0.10</span></span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Initiailizers</span></span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a>INIT_HE_UNIFORM <span class="op">=</span> tf.keras.initializers.he_uniform</span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a>INIT_GLOROT_UNIFORM <span class="op">=</span> tf.keras.initializers.glorot_uniform</span>
<span id="cb34-23"><a href="#cb34-23" aria-hidden="true" tabindex="-1"></a>INIT_ZEROS <span class="op">=</span> tf.keras.initializers.constant(<span class="fl">0.0</span>)</span>
<span id="cb34-24"><a href="#cb34-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Activations</span></span>
<span id="cb34-25"><a href="#cb34-25" aria-hidden="true" tabindex="-1"></a>GELU <span class="op">=</span> tf.keras.activations.gelu</span></code></pre></div>
</div>
<section id="landmark-embedding" class="cell markdown" data-papermill="{&quot;duration&quot;:2.4508e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:53.492645&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:53.468137&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Landmark Embedding</h1>
</section>
<div class="cell code" data-execution_count="25" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:53.544263Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:53.543229Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:53.552352Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:53.551474Z&quot;}" data-papermill="{&quot;duration&quot;:3.711e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:53.554368&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:53.517258&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Embeds a landmark using fully connected layers</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LandmarkEmbedding(tf.keras.Model):</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, units, name):</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(LandmarkEmbedding, <span class="va">self</span>).<span class="fu">__init__</span>(name<span class="op">=</span><span class="ss">f&#39;</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">_embedding&#39;</span>)</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.units <span class="op">=</span> units</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.supports_masking <span class="op">=</span> <span class="va">True</span></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> build(<span class="va">self</span>, input_shape):</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Embedding for missing landmark in frame, initizlied with zeros</span></span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.empty_embedding <span class="op">=</span> <span class="va">self</span>.add_weight(</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>            name<span class="op">=</span><span class="ss">f&#39;</span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>name<span class="sc">}</span><span class="ss">_empty_embedding&#39;</span>,</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>            shape<span class="op">=</span>[<span class="va">self</span>.units],</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>            initializer<span class="op">=</span>INIT_ZEROS,</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Embedding</span></span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dense <span class="op">=</span> tf.keras.Sequential([</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Dense(<span class="va">self</span>.units, name<span class="op">=</span><span class="ss">f&#39;</span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>name<span class="sc">}</span><span class="ss">_dense_1&#39;</span>, use_bias<span class="op">=</span><span class="va">False</span>, kernel_initializer<span class="op">=</span>INIT_GLOROT_UNIFORM, activation<span class="op">=</span>GELU),</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Dense(<span class="va">self</span>.units, name<span class="op">=</span><span class="ss">f&#39;</span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>name<span class="sc">}</span><span class="ss">_dense_2&#39;</span>, use_bias<span class="op">=</span><span class="va">False</span>, kernel_initializer<span class="op">=</span>INIT_HE_UNIFORM),</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>        ], name<span class="op">=</span><span class="ss">f&#39;</span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>name<span class="sc">}</span><span class="ss">_dense&#39;</span>)</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, x):</span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> tf.where(</span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Checks whether landmark is missing in frame</span></span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a>                tf.reduce_sum(x, axis<span class="op">=</span><span class="dv">2</span>, keepdims<span class="op">=</span><span class="va">True</span>) <span class="op">==</span> <span class="dv">0</span>,</span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a>                <span class="co"># If so, the empty embedding is used</span></span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.empty_embedding,</span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Otherwise the landmark data is embedded</span></span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.dense(x),</span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a>            )</span></code></pre></div>
</div>
<section id="embedding" class="cell markdown" data-papermill="{&quot;duration&quot;:2.3829e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:53.602530&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:53.578701&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Embedding</h1>
</section>
<div class="cell code" data-execution_count="26" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:53.653726Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:53.652798Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:53.661110Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:53.660189Z&quot;}" data-papermill="{&quot;duration&quot;:3.6321e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:53.663162&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:53.626841&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb36"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Creates embedding for each frame</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Embedding(tf.keras.Model):</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(Embedding, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.supports_masking <span class="op">=</span> <span class="va">True</span></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> build(<span class="va">self</span>, input_shape):</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Positional embedding for each frame index</span></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.positional_embedding <span class="op">=</span> tf.Variable(</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>            initial_value<span class="op">=</span>tf.zeros([N_TARGET_FRAMES, UNITS_ENCODER], dtype<span class="op">=</span>tf.float32),</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>            trainable<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>            name<span class="op">=</span><span class="st">&#39;embedding_positional_encoder&#39;</span>,</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Embedding layer for Landmarks</span></span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dominant_hand_embedding <span class="op">=</span> LandmarkEmbedding(UNITS_ENCODER, <span class="st">&#39;dominant_hand&#39;</span>)</span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, x, training<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Normalize</span></span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> tf.where(</span>
<span id="cb36-20"><a href="#cb36-20" aria-hidden="true" tabindex="-1"></a>                tf.math.equal(x, <span class="fl">0.0</span>),</span>
<span id="cb36-21"><a href="#cb36-21" aria-hidden="true" tabindex="-1"></a>                <span class="fl">0.0</span>,</span>
<span id="cb36-22"><a href="#cb36-22" aria-hidden="true" tabindex="-1"></a>                (x <span class="op">-</span> MEANS) <span class="op">/</span> STDS,</span>
<span id="cb36-23"><a href="#cb36-23" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb36-24"><a href="#cb36-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Dominant Hand</span></span>
<span id="cb36-25"><a href="#cb36-25" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.dominant_hand_embedding(x)</span>
<span id="cb36-26"><a href="#cb36-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add Positional Encoding</span></span>
<span id="cb36-27"><a href="#cb36-27" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x <span class="op">+</span> <span class="va">self</span>.positional_embedding</span>
<span id="cb36-28"><a href="#cb36-28" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb36-29"><a href="#cb36-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code></pre></div>
</div>
<section id="transformer" class="cell markdown" data-papermill="{&quot;duration&quot;:2.5127e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:53.713795&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:53.688668&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Transformer</h1>
</section>
<div class="cell code" data-execution_count="27" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:53.765194Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:53.764819Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:53.777397Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:53.776414Z&quot;}" data-papermill="{&quot;duration&quot;:4.073e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:53.779389&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:53.738659&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb37"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># based on: https://stackoverflow.com/questions/67342988/verifying-the-implementation-of-multihead-attention-in-transformer</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="co"># replaced softmax with softmax layer to support masked softmax</span></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> scaled_dot_product(q,k,v, softmax, attention_mask):</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">#calculates Q . K(transpose)</span></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>    qkt <span class="op">=</span> tf.matmul(q,k,transpose_b<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">#caculates scaling factor</span></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>    dk <span class="op">=</span> tf.math.sqrt(tf.cast(q.shape[<span class="op">-</span><span class="dv">1</span>],dtype<span class="op">=</span>tf.float32))</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>    scaled_qkt <span class="op">=</span> qkt<span class="op">/</span>dk</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>    softmax <span class="op">=</span> softmax(scaled_qkt, mask<span class="op">=</span>attention_mask)</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>    z <span class="op">=</span> tf.matmul(softmax,v)</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">#shape: (m,Tx,depth), same shape as q,k,v</span></span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> z</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MultiHeadAttention(tf.keras.layers.Layer):</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,d_model, num_of_heads, dropout, d_out<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(MultiHeadAttention,<span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.d_model <span class="op">=</span> d_model</span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_of_heads <span class="op">=</span> num_of_heads</span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.depth <span class="op">=</span> d_model<span class="op">//</span>num_of_heads</span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.wq <span class="op">=</span> [tf.keras.layers.Dense(<span class="va">self</span>.depth<span class="op">//</span><span class="dv">2</span>, use_bias<span class="op">=</span><span class="va">False</span>) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_of_heads)]</span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.wk <span class="op">=</span> [tf.keras.layers.Dense(<span class="va">self</span>.depth<span class="op">//</span><span class="dv">2</span>, use_bias<span class="op">=</span><span class="va">False</span>) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_of_heads)]</span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.wv <span class="op">=</span> [tf.keras.layers.Dense(<span class="va">self</span>.depth<span class="op">//</span><span class="dv">2</span>, use_bias<span class="op">=</span><span class="va">False</span>) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_of_heads)]</span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.wo <span class="op">=</span> tf.keras.layers.Dense(d_model <span class="cf">if</span> d_out <span class="kw">is</span> <span class="va">None</span> <span class="cf">else</span> d_out, use_bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.softmax <span class="op">=</span> tf.keras.layers.Softmax()</span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.do <span class="op">=</span> tf.keras.layers.Dropout(dropout)</span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.supports_masking <span class="op">=</span> <span class="va">True</span></span>
<span id="cb37-27"><a href="#cb37-27" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb37-28"><a href="#cb37-28" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, q, k, v, attention_mask<span class="op">=</span><span class="va">None</span>, training<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb37-29"><a href="#cb37-29" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb37-30"><a href="#cb37-30" aria-hidden="true" tabindex="-1"></a>        multi_attn <span class="op">=</span> []</span>
<span id="cb37-31"><a href="#cb37-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.num_of_heads):</span>
<span id="cb37-32"><a href="#cb37-32" aria-hidden="true" tabindex="-1"></a>            Q <span class="op">=</span> <span class="va">self</span>.wq[i](q)</span>
<span id="cb37-33"><a href="#cb37-33" aria-hidden="true" tabindex="-1"></a>            K <span class="op">=</span> <span class="va">self</span>.wk[i](k)</span>
<span id="cb37-34"><a href="#cb37-34" aria-hidden="true" tabindex="-1"></a>            V <span class="op">=</span> <span class="va">self</span>.wv[i](v)</span>
<span id="cb37-35"><a href="#cb37-35" aria-hidden="true" tabindex="-1"></a>            multi_attn.append(scaled_dot_product(Q,K,V, <span class="va">self</span>.softmax, attention_mask))</span>
<span id="cb37-36"><a href="#cb37-36" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb37-37"><a href="#cb37-37" aria-hidden="true" tabindex="-1"></a>        multi_head <span class="op">=</span> tf.concat(multi_attn, axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb37-38"><a href="#cb37-38" aria-hidden="true" tabindex="-1"></a>        multi_head_attention <span class="op">=</span> <span class="va">self</span>.wo(multi_head)</span>
<span id="cb37-39"><a href="#cb37-39" aria-hidden="true" tabindex="-1"></a>        multi_head_attention <span class="op">=</span> <span class="va">self</span>.do(multi_head_attention, training<span class="op">=</span>training)</span>
<span id="cb37-40"><a href="#cb37-40" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb37-41"><a href="#cb37-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> multi_head_attention</span></code></pre></div>
</div>
<section id="encoder" class="cell markdown" data-papermill="{&quot;duration&quot;:2.4245e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:53.828275&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:53.804030&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Encoder</h1>
<p><a href="https://keras.io/examples/nlp/neural_machine_translation_with_transformer/">source</a></p>
</section>
<div class="cell code" data-execution_count="28" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:53.880216Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:53.879240Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:53.892432Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:53.891495Z&quot;}" data-papermill="{&quot;duration&quot;:4.1438e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:53.894476&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:53.853038&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb38"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Encoder based on multiple transformer blocks</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Encoder(tf.keras.Model):</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_blocks):</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(Encoder, <span class="va">self</span>).<span class="fu">__init__</span>(name<span class="op">=</span><span class="st">&#39;encoder&#39;</span>)</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_blocks <span class="op">=</span> num_blocks</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.supports_masking <span class="op">=</span> <span class="va">True</span></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> build(<span class="va">self</span>, input_shape):</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ln_1s <span class="op">=</span> []</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mhas <span class="op">=</span> []</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ln_2s <span class="op">=</span> []</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mlps <span class="op">=</span> []</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Make Transformer Blocks</span></span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.num_blocks):</span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a>            <span class="co"># First Layer Normalisation</span></span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.ln_1s.append(tf.keras.layers.LayerNormalization(epsilon<span class="op">=</span>LAYER_NORM_EPS))</span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Multi Head Attention</span></span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.mhas.append(MultiHeadAttention(UNITS_ENCODER, NUM_HEADS, MHA_DROPOUT_RATIO))</span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Second Layer Normalisation</span></span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.ln_2s.append(tf.keras.layers.LayerNormalization(epsilon<span class="op">=</span>LAYER_NORM_EPS))</span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Multi Layer Perception</span></span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.mlps.append(tf.keras.Sequential([</span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a>                tf.keras.layers.Dense(UNITS_ENCODER <span class="op">*</span> MLP_RATIO, activation<span class="op">=</span>GELU, kernel_initializer<span class="op">=</span>INIT_GLOROT_UNIFORM, use_bias<span class="op">=</span><span class="va">False</span>),</span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a>                tf.keras.layers.Dropout(MLP_DROPOUT_RATIO),</span>
<span id="cb38-25"><a href="#cb38-25" aria-hidden="true" tabindex="-1"></a>                tf.keras.layers.Dense(UNITS_ENCODER, kernel_initializer<span class="op">=</span>INIT_HE_UNIFORM, use_bias<span class="op">=</span><span class="va">False</span>),</span>
<span id="cb38-26"><a href="#cb38-26" aria-hidden="true" tabindex="-1"></a>            ]))</span>
<span id="cb38-27"><a href="#cb38-27" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Optional Projection to Decoder Dimension</span></span>
<span id="cb38-28"><a href="#cb38-28" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> UNITS_ENCODER <span class="op">!=</span> UNITS_DECODER:</span>
<span id="cb38-29"><a href="#cb38-29" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.dense_out <span class="op">=</span> tf.keras.layers.Dense(UNITS_DECODER, kernel_initializer<span class="op">=</span>INIT_GLOROT_UNIFORM, use_bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb38-30"><a href="#cb38-30" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.apply_dense_out <span class="op">=</span> <span class="va">True</span></span>
<span id="cb38-31"><a href="#cb38-31" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb38-32"><a href="#cb38-32" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.apply_dense_out <span class="op">=</span> <span class="va">False</span></span>
<span id="cb38-33"><a href="#cb38-33" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb38-34"><a href="#cb38-34" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, x, x_inp, training<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb38-35"><a href="#cb38-35" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Attention mask to ignore missing frames</span></span>
<span id="cb38-36"><a href="#cb38-36" aria-hidden="true" tabindex="-1"></a>        attention_mask <span class="op">=</span> tf.where(tf.math.reduce_sum(x_inp, axis<span class="op">=</span>[<span class="dv">2</span>]) <span class="op">==</span> <span class="fl">0.0</span>, <span class="fl">0.0</span>, <span class="fl">1.0</span>)</span>
<span id="cb38-37"><a href="#cb38-37" aria-hidden="true" tabindex="-1"></a>        attention_mask <span class="op">=</span> tf.expand_dims(attention_mask, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb38-38"><a href="#cb38-38" aria-hidden="true" tabindex="-1"></a>        attention_mask <span class="op">=</span> tf.repeat(attention_mask, repeats<span class="op">=</span>N_TARGET_FRAMES, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb38-39"><a href="#cb38-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Iterate input over transformer blocks</span></span>
<span id="cb38-40"><a href="#cb38-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> ln_1, mha, ln_2, mlp <span class="kw">in</span> <span class="bu">zip</span>(<span class="va">self</span>.ln_1s, <span class="va">self</span>.mhas, <span class="va">self</span>.ln_2s, <span class="va">self</span>.mlps):</span>
<span id="cb38-41"><a href="#cb38-41" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> ln_1(x <span class="op">+</span> mha(x, x, x, attention_mask<span class="op">=</span>attention_mask))</span>
<span id="cb38-42"><a href="#cb38-42" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> ln_2(x <span class="op">+</span> mlp(x))</span>
<span id="cb38-43"><a href="#cb38-43" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb38-44"><a href="#cb38-44" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Optional Projection to Decoder Dimension</span></span>
<span id="cb38-45"><a href="#cb38-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.apply_dense_out:</span>
<span id="cb38-46"><a href="#cb38-46" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> <span class="va">self</span>.dense_out(x)</span>
<span id="cb38-47"><a href="#cb38-47" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb38-48"><a href="#cb38-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code></pre></div>
</div>
<section id="decoder" class="cell markdown" data-papermill="{&quot;duration&quot;:2.4624e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:53.943518&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:53.918894&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Decoder</h1>
</section>
<div class="cell code" data-execution_count="29" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:53.994819Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:53.994473Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:54.012561Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:54.011515Z&quot;}" data-papermill="{&quot;duration&quot;:4.6582e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:54.014771&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:53.968189&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb39"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Decoder based on multiple transformer blocks</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Decoder(tf.keras.Model):</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_blocks):</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(Decoder, <span class="va">self</span>).<span class="fu">__init__</span>(name<span class="op">=</span><span class="st">&#39;decoder&#39;</span>)</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_blocks <span class="op">=</span> num_blocks</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.supports_masking <span class="op">=</span> <span class="va">True</span></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> build(<span class="va">self</span>, input_shape):</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Positional Embedding, initialized with zeros</span></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.positional_embedding <span class="op">=</span> tf.Variable(</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>            initial_value<span class="op">=</span>tf.zeros([N_TARGET_FRAMES, UNITS_DECODER], dtype<span class="op">=</span>tf.float32),</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>            trainable<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>            name<span class="op">=</span><span class="st">&#39;embedding_positional_encoder&#39;</span>,</span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Character Embedding</span></span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.char_emb <span class="op">=</span> tf.keras.layers.Embedding(N_UNIQUE_CHARACTERS, UNITS_DECODER, embeddings_initializer<span class="op">=</span>INIT_ZEROS)</span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Positional Encoder MHA</span></span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pos_emb_mha <span class="op">=</span> MultiHeadAttention(UNITS_DECODER, NUM_HEADS, MHA_DROPOUT_RATIO)</span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pos_emb_ln <span class="op">=</span> tf.keras.layers.LayerNormalization(epsilon<span class="op">=</span>LAYER_NORM_EPS)</span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># First Layer Normalisation</span></span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ln_1s <span class="op">=</span> []</span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mhas <span class="op">=</span> []</span>
<span id="cb39-23"><a href="#cb39-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ln_2s <span class="op">=</span> []</span>
<span id="cb39-24"><a href="#cb39-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mlps <span class="op">=</span> []</span>
<span id="cb39-25"><a href="#cb39-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Make Transformer Blocks</span></span>
<span id="cb39-26"><a href="#cb39-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.num_blocks):</span>
<span id="cb39-27"><a href="#cb39-27" aria-hidden="true" tabindex="-1"></a>            <span class="co"># First Layer Normalisation</span></span>
<span id="cb39-28"><a href="#cb39-28" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.ln_1s.append(tf.keras.layers.LayerNormalization(epsilon<span class="op">=</span>LAYER_NORM_EPS))</span>
<span id="cb39-29"><a href="#cb39-29" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Multi Head Attention</span></span>
<span id="cb39-30"><a href="#cb39-30" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.mhas.append(MultiHeadAttention(UNITS_DECODER, NUM_HEADS, MHA_DROPOUT_RATIO))</span>
<span id="cb39-31"><a href="#cb39-31" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Second Layer Normalisation</span></span>
<span id="cb39-32"><a href="#cb39-32" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.ln_2s.append(tf.keras.layers.LayerNormalization(epsilon<span class="op">=</span>LAYER_NORM_EPS))</span>
<span id="cb39-33"><a href="#cb39-33" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Multi Layer Perception</span></span>
<span id="cb39-34"><a href="#cb39-34" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.mlps.append(tf.keras.Sequential([</span>
<span id="cb39-35"><a href="#cb39-35" aria-hidden="true" tabindex="-1"></a>                tf.keras.layers.Dense(UNITS_DECODER <span class="op">*</span> MLP_RATIO, activation<span class="op">=</span>GELU, kernel_initializer<span class="op">=</span>INIT_GLOROT_UNIFORM, use_bias<span class="op">=</span><span class="va">False</span>),</span>
<span id="cb39-36"><a href="#cb39-36" aria-hidden="true" tabindex="-1"></a>                tf.keras.layers.Dropout(MLP_DROPOUT_RATIO),</span>
<span id="cb39-37"><a href="#cb39-37" aria-hidden="true" tabindex="-1"></a>                tf.keras.layers.Dense(UNITS_DECODER, kernel_initializer<span class="op">=</span>INIT_HE_UNIFORM, use_bias<span class="op">=</span><span class="va">False</span>),</span>
<span id="cb39-38"><a href="#cb39-38" aria-hidden="true" tabindex="-1"></a>            ]))</span>
<span id="cb39-39"><a href="#cb39-39" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb39-40"><a href="#cb39-40" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_causal_attention_mask(<span class="va">self</span>, B):</span>
<span id="cb39-41"><a href="#cb39-41" aria-hidden="true" tabindex="-1"></a>        i <span class="op">=</span> tf.<span class="bu">range</span>(N_TARGET_FRAMES)[:, tf.newaxis]</span>
<span id="cb39-42"><a href="#cb39-42" aria-hidden="true" tabindex="-1"></a>        j <span class="op">=</span> tf.<span class="bu">range</span>(N_TARGET_FRAMES)</span>
<span id="cb39-43"><a href="#cb39-43" aria-hidden="true" tabindex="-1"></a>        mask <span class="op">=</span> tf.cast(i <span class="op">&gt;=</span> j, dtype<span class="op">=</span>tf.int32)</span>
<span id="cb39-44"><a href="#cb39-44" aria-hidden="true" tabindex="-1"></a>        mask <span class="op">=</span> tf.reshape(mask, (<span class="dv">1</span>, N_TARGET_FRAMES, N_TARGET_FRAMES))</span>
<span id="cb39-45"><a href="#cb39-45" aria-hidden="true" tabindex="-1"></a>        mult <span class="op">=</span> tf.concat(</span>
<span id="cb39-46"><a href="#cb39-46" aria-hidden="true" tabindex="-1"></a>            [tf.expand_dims(B, <span class="op">-</span><span class="dv">1</span>), tf.constant([<span class="dv">1</span>, <span class="dv">1</span>], dtype<span class="op">=</span>tf.int32)],</span>
<span id="cb39-47"><a href="#cb39-47" aria-hidden="true" tabindex="-1"></a>            axis<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb39-48"><a href="#cb39-48" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb39-49"><a href="#cb39-49" aria-hidden="true" tabindex="-1"></a>        mask <span class="op">=</span> tf.tile(mask, mult)</span>
<span id="cb39-50"><a href="#cb39-50" aria-hidden="true" tabindex="-1"></a>        mask <span class="op">=</span> tf.cast(mask, tf.float32)</span>
<span id="cb39-51"><a href="#cb39-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> mask</span>
<span id="cb39-52"><a href="#cb39-52" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb39-53"><a href="#cb39-53" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, encoder_outputs, phrase, training<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb39-54"><a href="#cb39-54" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Batch Size</span></span>
<span id="cb39-55"><a href="#cb39-55" aria-hidden="true" tabindex="-1"></a>        B <span class="op">=</span> tf.shape(encoder_outputs)[<span class="dv">0</span>]</span>
<span id="cb39-56"><a href="#cb39-56" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Cast to INT32</span></span>
<span id="cb39-57"><a href="#cb39-57" aria-hidden="true" tabindex="-1"></a>        phrase <span class="op">=</span> tf.cast(phrase, tf.int32)</span>
<span id="cb39-58"><a href="#cb39-58" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Prepend SOS Token</span></span>
<span id="cb39-59"><a href="#cb39-59" aria-hidden="true" tabindex="-1"></a>        phrase <span class="op">=</span> tf.pad(phrase, [[<span class="dv">0</span>,<span class="dv">0</span>], [<span class="dv">1</span>,<span class="dv">0</span>]], constant_values<span class="op">=</span>SOS_TOKEN, name<span class="op">=</span><span class="st">&#39;prepend_sos_token&#39;</span>)</span>
<span id="cb39-60"><a href="#cb39-60" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Pad With PAD Token</span></span>
<span id="cb39-61"><a href="#cb39-61" aria-hidden="true" tabindex="-1"></a>        phrase <span class="op">=</span> tf.pad(phrase, [[<span class="dv">0</span>,<span class="dv">0</span>], [<span class="dv">0</span>,N_TARGET_FRAMES<span class="op">-</span>MAX_PHRASE_LENGTH<span class="op">-</span><span class="dv">1</span>]], constant_values<span class="op">=</span>PAD_TOKEN, name<span class="op">=</span><span class="st">&#39;append_pad_token&#39;</span>)</span>
<span id="cb39-62"><a href="#cb39-62" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Causal Mask</span></span>
<span id="cb39-63"><a href="#cb39-63" aria-hidden="true" tabindex="-1"></a>        causal_mask <span class="op">=</span> <span class="va">self</span>.get_causal_attention_mask(B)</span>
<span id="cb39-64"><a href="#cb39-64" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Positional Embedding</span></span>
<span id="cb39-65"><a href="#cb39-65" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.positional_embedding <span class="op">+</span> <span class="va">self</span>.char_emb(phrase)</span>
<span id="cb39-66"><a href="#cb39-66" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Causal Attention</span></span>
<span id="cb39-67"><a href="#cb39-67" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.pos_emb_ln(x <span class="op">+</span> <span class="va">self</span>.pos_emb_mha(x, x, x, attention_mask<span class="op">=</span>causal_mask))</span>
<span id="cb39-68"><a href="#cb39-68" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Iterate input over transformer blocks</span></span>
<span id="cb39-69"><a href="#cb39-69" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> ln_1, mha, ln_2, mlp <span class="kw">in</span> <span class="bu">zip</span>(<span class="va">self</span>.ln_1s, <span class="va">self</span>.mhas, <span class="va">self</span>.ln_2s, <span class="va">self</span>.mlps):</span>
<span id="cb39-70"><a href="#cb39-70" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> ln_1(x <span class="op">+</span> mha(x, encoder_outputs, encoder_outputs, attention_mask<span class="op">=</span>causal_mask))</span>
<span id="cb39-71"><a href="#cb39-71" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> ln_2(x <span class="op">+</span> mlp(x))</span>
<span id="cb39-72"><a href="#cb39-72" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Slice 31 Characters</span></span>
<span id="cb39-73"><a href="#cb39-73" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> tf.<span class="bu">slice</span>(x, [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>], [<span class="op">-</span><span class="dv">1</span>, MAX_PHRASE_LENGTH, <span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb39-74"><a href="#cb39-74" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb39-75"><a href="#cb39-75" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="30" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:54.070281Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:54.069163Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:54.135042Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:54.134093Z&quot;}" data-papermill="{&quot;duration&quot;:9.4639e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:54.137348&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:54.042709&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb40"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Causal Attention to make decoder not attent to future characters which it needs to predict</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_causal_attention_mask(B):</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> tf.<span class="bu">range</span>(N_TARGET_FRAMES)[:, tf.newaxis]</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>    j <span class="op">=</span> tf.<span class="bu">range</span>(N_TARGET_FRAMES)</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> tf.cast(i <span class="op">&gt;=</span> j, dtype<span class="op">=</span>tf.int32)</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> tf.reshape(mask, (<span class="dv">1</span>, N_TARGET_FRAMES, N_TARGET_FRAMES))</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>    mult <span class="op">=</span> tf.concat(</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>        [tf.expand_dims(B, <span class="op">-</span><span class="dv">1</span>), tf.constant([<span class="dv">1</span>, <span class="dv">1</span>], dtype<span class="op">=</span>tf.int32)],</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>        axis<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> tf.tile(mask, mult)</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> tf.cast(mask, tf.float32)</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> mask</span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>get_causal_attention_mask(<span class="dv">1</span>)</span></code></pre></div>
<div class="output execute_result" data-execution_count="30">
<pre><code>&lt;tf.Tensor: shape=(1, 128, 128), dtype=float32, numpy=
array([[[1., 0., 0., ..., 0., 0., 0.],
        [1., 1., 0., ..., 0., 0., 0.],
        [1., 1., 1., ..., 0., 0., 0.],
        ...,
        [1., 1., 1., ..., 1., 0., 0.],
        [1., 1., 1., ..., 1., 1., 0.],
        [1., 1., 1., ..., 1., 1., 1.]]], dtype=float32)&gt;</code></pre>
</div>
</div>
<section id="non-padsoseos-token-accuracy" class="cell markdown" data-papermill="{&quot;duration&quot;:2.4935e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:54.189242&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:54.164307&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Non Pad/SOS/EOS Token Accuracy</h1>
</section>
<div class="cell code" data-execution_count="31" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:54.240687Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:54.240332Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:54.249171Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:54.248099Z&quot;}" data-papermill="{&quot;duration&quot;:3.7227e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:54.251228&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:54.214001&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb42"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># TopK accuracy for multi dimensional output</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TopKAccuracy(tf.keras.metrics.Metric):</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, k, <span class="op">**</span>kwargs):</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(TopKAccuracy, <span class="va">self</span>).<span class="fu">__init__</span>(name<span class="op">=</span><span class="ss">f&#39;top</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss">acc&#39;</span>, <span class="op">**</span>kwargs)</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.top_k_acc <span class="op">=</span> tf.keras.metrics.SparseTopKCategoricalAccuracy(k<span class="op">=</span>k)</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> update_state(<span class="va">self</span>, y_true, y_pred, sample_weight<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>        y_true <span class="op">=</span> tf.reshape(y_true, [<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> tf.reshape(y_pred, [<span class="op">-</span><span class="dv">1</span>, N_UNIQUE_CHARACTERS])</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>        character_idxs <span class="op">=</span> tf.where(y_true <span class="op">&lt;</span> N_UNIQUE_CHARACTERS0)</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>        y_true <span class="op">=</span> tf.gather(y_true, character_idxs, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> tf.gather(y_pred, character_idxs, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.top_k_acc.update_state(y_true, y_pred)</span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> result(<span class="va">self</span>):</span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.top_k_acc.result()</span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> reset_state(<span class="va">self</span>):</span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.top_k_acc.reset_state()</span></code></pre></div>
</div>
<section id="loss-weights" class="cell markdown" data-papermill="{&quot;duration&quot;:2.4945e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:54.301243&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:54.276298&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Loss Weights</h1>
</section>
<div class="cell code" data-execution_count="32" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:54.353749Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:54.352794Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:54.358249Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:54.357342Z&quot;}" data-papermill="{&quot;duration&quot;:3.3995e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:54.360318&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:54.326323&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb43"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create Initial Loss Weights All Set To 1</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>loss_weights <span class="op">=</span> np.ones(N_UNIQUE_CHARACTERS, dtype<span class="op">=</span>np.float32)</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Set Loss Weight Of Pad Token To 0</span></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>loss_weights[PAD_TOKEN] <span class="op">=</span> <span class="dv">0</span></span></code></pre></div>
</div>
<section id="sparse-categorical-crossentropy-with-label-smoothing" class="cell markdown" data-papermill="{&quot;duration&quot;:2.4662e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:54.409907&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:54.385245&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Sparse Categorical Crossentropy With Label Smoothing¶</h1>
</section>
<div class="cell code" data-execution_count="33" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:54.460953Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:54.459992Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:54.466913Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:54.466010Z&quot;}" data-papermill="{&quot;duration&quot;:3.4321e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:54.468872&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:54.434551&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb44"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># source:: https://stackoverflow.com/questions/60689185/label-smoothing-for-sparse-categorical-crossentropy</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> scce_with_ls(y_true, y_pred):</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Filter Pad Tokens</span></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>    idxs <span class="op">=</span> tf.where(y_true <span class="op">!=</span> PAD_TOKEN)</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>    y_true <span class="op">=</span> tf.gather_nd(y_true, idxs)</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> tf.gather_nd(y_pred, idxs)</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># One Hot Encode Sparsely Encoded Target Sign</span></span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>    y_true <span class="op">=</span> tf.cast(y_true, tf.int32)</span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>    y_true <span class="op">=</span> tf.one_hot(y_true, N_UNIQUE_CHARACTERS, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Categorical Crossentropy with native label smoothing support</span></span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> tf.keras.losses.categorical_crossentropy(y_true, y_pred, label_smoothing<span class="op">=</span><span class="fl">0.25</span>, from_logits<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> tf.math.reduce_mean(loss)</span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> loss</span></code></pre></div>
</div>
<section id="model" class="cell markdown" data-papermill="{&quot;duration&quot;:2.5057e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:54.518693&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:54.493636&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Model</h1>
</section>
<div class="cell code" data-execution_count="34" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:54.570291Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:54.569589Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:54.579786Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:54.578838Z&quot;}" data-papermill="{&quot;duration&quot;:3.826e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:54.581784&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:54.543524&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb45"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_model():</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Inputs</span></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>    frames_inp <span class="op">=</span> tf.keras.layers.Input([N_TARGET_FRAMES, N_COLS], dtype<span class="op">=</span>tf.float32, name<span class="op">=</span><span class="st">&#39;frames&#39;</span>)</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>    phrase_inp <span class="op">=</span> tf.keras.layers.Input([MAX_PHRASE_LENGTH], dtype<span class="op">=</span>tf.int32, name<span class="op">=</span><span class="st">&#39;phrase&#39;</span>)</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Frames</span></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> frames_inp</span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Masking</span></span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> tf.keras.layers.Masking(mask_value<span class="op">=</span><span class="fl">0.0</span>, input_shape<span class="op">=</span>(N_TARGET_FRAMES, N_COLS))(x)</span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Embedding</span></span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Embedding()(x)</span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Encoder Transformer Blocks</span></span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Encoder(NUM_BLOCKS_ENCODER)(x, frames_inp)</span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Decoder</span></span>
<span id="cb45-18"><a href="#cb45-18" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Decoder(NUM_BLOCKS_DECODER)(x, phrase_inp)</span>
<span id="cb45-19"><a href="#cb45-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb45-20"><a href="#cb45-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Classifier</span></span>
<span id="cb45-21"><a href="#cb45-21" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> tf.keras.Sequential([</span>
<span id="cb45-22"><a href="#cb45-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Dropout</span></span>
<span id="cb45-23"><a href="#cb45-23" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.Dropout(CLASSIFIER_DROPOUT_RATIO),</span>
<span id="cb45-24"><a href="#cb45-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Output Neurons</span></span>
<span id="cb45-25"><a href="#cb45-25" aria-hidden="true" tabindex="-1"></a>        tf.keras.layers.Dense(N_UNIQUE_CHARACTERS, activation<span class="op">=</span>tf.keras.activations.linear, kernel_initializer<span class="op">=</span>INIT_HE_UNIFORM, use_bias<span class="op">=</span><span class="va">False</span>),</span>
<span id="cb45-26"><a href="#cb45-26" aria-hidden="true" tabindex="-1"></a>    ], name<span class="op">=</span><span class="st">&#39;classifier&#39;</span>)(x)</span>
<span id="cb45-27"><a href="#cb45-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb45-28"><a href="#cb45-28" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> x</span>
<span id="cb45-29"><a href="#cb45-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb45-30"><a href="#cb45-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create Tensorflow Model</span></span>
<span id="cb45-31"><a href="#cb45-31" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> tf.keras.models.Model(inputs<span class="op">=</span>[frames_inp, phrase_inp], outputs<span class="op">=</span>outputs)</span>
<span id="cb45-32"><a href="#cb45-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb45-33"><a href="#cb45-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Categorical Crossentropy Loss With Label Smoothing</span></span>
<span id="cb45-34"><a href="#cb45-34" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> scce_with_ls</span>
<span id="cb45-35"><a href="#cb45-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb45-36"><a href="#cb45-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Adam Optimizer</span></span>
<span id="cb45-37"><a href="#cb45-37" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> tfa.optimizers.RectifiedAdam(sma_threshold<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb45-38"><a href="#cb45-38" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> tfa.optimizers.Lookahead(optimizer, sync_period<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb45-39"><a href="#cb45-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-40"><a href="#cb45-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># TopK Metrics</span></span>
<span id="cb45-41"><a href="#cb45-41" aria-hidden="true" tabindex="-1"></a>    metrics <span class="op">=</span> [</span>
<span id="cb45-42"><a href="#cb45-42" aria-hidden="true" tabindex="-1"></a>        TopKAccuracy(<span class="dv">1</span>),</span>
<span id="cb45-43"><a href="#cb45-43" aria-hidden="true" tabindex="-1"></a>        TopKAccuracy(<span class="dv">5</span>),</span>
<span id="cb45-44"><a href="#cb45-44" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb45-45"><a href="#cb45-45" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb45-46"><a href="#cb45-46" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">compile</span>(</span>
<span id="cb45-47"><a href="#cb45-47" aria-hidden="true" tabindex="-1"></a>        loss<span class="op">=</span>loss,</span>
<span id="cb45-48"><a href="#cb45-48" aria-hidden="true" tabindex="-1"></a>        optimizer<span class="op">=</span>optimizer,</span>
<span id="cb45-49"><a href="#cb45-49" aria-hidden="true" tabindex="-1"></a>        metrics<span class="op">=</span>metrics,</span>
<span id="cb45-50"><a href="#cb45-50" aria-hidden="true" tabindex="-1"></a>        loss_weights<span class="op">=</span>loss_weights,</span>
<span id="cb45-51"><a href="#cb45-51" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb45-52"><a href="#cb45-52" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb45-53"><a href="#cb45-53" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="35" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:54.634393Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:54.633465Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:54.639768Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:54.638629Z&quot;}" data-papermill="{&quot;duration&quot;:3.5009e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:54.641801&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:54.606792&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb46"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Input data</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k, v <span class="kw">in</span> X_batch.items():</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&#39;</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>v<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>frames: (1024, 128, 164)
phrase: (1024, 32)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="36" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:54.692466Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:54.691898Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:57.823793Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:57.822844Z&quot;}" data-papermill="{&quot;duration&quot;:3.159973,&quot;end_time&quot;:&quot;2023-07-02T11:33:57.826278&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:54.666305&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb48"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>tf.keras.backend.clear_session()</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> get_model()</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="37" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:57.880830Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:57.880496Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:58.012178Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:58.011400Z&quot;}" data-papermill="{&quot;duration&quot;:0.237637,&quot;end_time&quot;:&quot;2023-07-02T11:33:58.088939&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:57.851302&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb49"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot model summary</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>model.summary(expand_nested<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Model: &quot;model&quot;
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 frames (InputLayer)            [(None, 128, 164)]   0           []                               
                                                                                                  
 masking (Masking)              (None, 128, 164)     0           [&#39;frames[0][0]&#39;]                 
                                                                                                  
 embedding (Embedding)          (None, 128, 384)     259968      [&#39;masking[0][0]&#39;]                
|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|
| dominant_hand_embedding (Landm  multiple          210816      []                               |
| arkEmbedding)                                                                                  |
||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||
|| dominant_hand_embedding_dense   (None, 128, 384)  210432    []                               ||
|| (Sequential)                                                                                 ||
|||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|||
||| dominant_hand_embedding_dense_  (None, 128, 384)  62976   []                               |||
||| 1 (Dense)                                                                                  |||
|||                                                                                            |||
||| dominant_hand_embedding_dense_  (None, 128, 384)  147456  []                               |||
||| 2 (Dense)                                                                                  |||
||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||
|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 encoder (Encoder)              (None, 128, 256)     2757120     [&#39;embedding[0][0]&#39;,              
                                                                  &#39;frames[0][0]&#39;]                 
|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|
| layer_normalization (LayerNorm  multiple          768         []                               |
| alization)                                                                                     |
|                                                                                                |
| layer_normalization_2 (LayerNo  multiple          768         []                               |
| rmalization)                                                                                   |
|                                                                                                |
| layer_normalization_4 (LayerNo  multiple          768         []                               |
| rmalization)                                                                                   |
|                                                                                                |
| multi_head_attention (MultiHea  multiple          294912      []                               |
| dAttention)                                                                                    |
|                                                                                                |
| multi_head_attention_1 (MultiH  multiple          294912      []                               |
| eadAttention)                                                                                  |
|                                                                                                |
| multi_head_attention_2 (MultiH  multiple          294912      []                               |
| eadAttention)                                                                                  |
|                                                                                                |
| layer_normalization_1 (LayerNo  multiple          768         []                               |
| rmalization)                                                                                   |
|                                                                                                |
| layer_normalization_3 (LayerNo  multiple          768         []                               |
| rmalization)                                                                                   |
|                                                                                                |
| layer_normalization_5 (LayerNo  multiple          768         []                               |
| rmalization)                                                                                   |
|                                                                                                |
| sequential (Sequential)      (None, 128, 384)     589824      []                               |
||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||
|| dense_13 (Dense)           (None, 128, 768)     294912      []                               ||
||                                                                                              ||
|| dropout_1 (Dropout)        (None, 128, 768)     0           []                               ||
||                                                                                              ||
|| dense_14 (Dense)           (None, 128, 384)     294912      []                               ||
|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|
| sequential_1 (Sequential)    (None, 128, 384)     589824      []                               |
||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||
|| dense_29 (Dense)           (None, 128, 768)     294912      []                               ||
||                                                                                              ||
|| dropout_3 (Dropout)        (None, 128, 768)     0           []                               ||
||                                                                                              ||
|| dense_30 (Dense)           (None, 128, 384)     294912      []                               ||
|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|
| sequential_2 (Sequential)    (None, 128, 384)     589824      []                               |
||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||
|| dense_45 (Dense)           (None, 128, 768)     294912      []                               ||
||                                                                                              ||
|| dropout_5 (Dropout)        (None, 128, 768)     0           []                               ||
||                                                                                              ||
|| dense_46 (Dense)           (None, 128, 384)     294912      []                               ||
|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|
| dense_47 (Dense)             multiple             98304       []                               |
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 phrase (InputLayer)            [(None, 32)]         0           []                               
                                                                                                  
 decoder (Decoder)              (None, 32, 256)      968704      [&#39;encoder[0][0]&#39;,                
                                                                  &#39;phrase[0][0]&#39;]                 
|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|
| embedding (Embedding)        multiple             15872       []                               |
|                                                                                                |
| multi_head_attention (MultiHea  multiple          131072      []                               |
| dAttention)                                                                                    |
|                                                                                                |
| layer_normalization (LayerNorm  multiple          512         []                               |
| alization)                                                                                     |
|                                                                                                |
| layer_normalization_1 (LayerNo  multiple          512         []                               |
| rmalization)                                                                                   |
|                                                                                                |
| layer_normalization_3 (LayerNo  multiple          512         []                               |
| rmalization)                                                                                   |
|                                                                                                |
| multi_head_attention_1 (MultiH  multiple          131072      []                               |
| eadAttention)                                                                                  |
|                                                                                                |
| multi_head_attention_2 (MultiH  multiple          131072      []                               |
| eadAttention)                                                                                  |
|                                                                                                |
| layer_normalization_2 (LayerNo  multiple          512         []                               |
| rmalization)                                                                                   |
|                                                                                                |
| layer_normalization_4 (LayerNo  multiple          512         []                               |
| rmalization)                                                                                   |
|                                                                                                |
| sequential (Sequential)      (None, 128, 256)     262144      []                               |
||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||
|| dense_26 (Dense)           (None, 128, 512)     131072      []                               ||
||                                                                                              ||
|| dropout_2 (Dropout)        (None, 128, 512)     0           []                               ||
||                                                                                              ||
|| dense_27 (Dense)           (None, 128, 256)     131072      []                               ||
|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|
| sequential_1 (Sequential)    (None, 128, 256)     262144      []                               |
||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||
|| dense_41 (Dense)           (None, 128, 512)     131072      []                               ||
||                                                                                              ||
|| dropout_4 (Dropout)        (None, 128, 512)     0           []                               ||
||                                                                                              ||
|| dense_42 (Dense)           (None, 128, 256)     131072      []                               ||
|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 classifier (Sequential)        (None, 32, 62)       15872       [&#39;decoder[0][0]&#39;]                
|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|
| dropout (Dropout)            (None, 32, 256)      0           []                               |
|                                                                                                |
| dense (Dense)                (None, 32, 62)       15872       []                               |
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
==================================================================================================
Total params: 4,001,664
Trainable params: 4,001,664
Non-trainable params: 0
__________________________________________________________________________________________________
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="38" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:58.162428Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:58.162039Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:33:58.429957Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:33:58.428977Z&quot;}" data-papermill="{&quot;duration&quot;:0.307642,&quot;end_time&quot;:&quot;2023-07-02T11:33:58.432321&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:58.124679&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb51"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Model Architecture</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>tf.keras.utils.plot_model(model, show_shapes<span class="op">=</span><span class="va">True</span>, show_dtype<span class="op">=</span><span class="va">True</span>, show_layer_names<span class="op">=</span><span class="va">True</span>, expand_nested<span class="op">=</span><span class="va">True</span>, show_layer_activations<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
<div class="output execute_result" data-execution_count="38">
<p><img src="93f0d5467cdce491a0ab0f2289f77ebc705af9e6.png" /></p>
</div>
</div>
<section id="verify-training-flag" class="cell markdown" data-papermill="{&quot;duration&quot;:3.7937e-2,&quot;end_time&quot;:&quot;2023-07-02T11:33:58.509486&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:58.471549&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Verify Training Flag</h1>
</section>
<div class="cell code" data-execution_count="39" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:33:58.587694Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:33:58.587333Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:34:04.073080Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:34:04.072093Z&quot;}" data-papermill="{&quot;duration&quot;:5.527641,&quot;end_time&quot;:&quot;2023-07-02T11:34:04.075359&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:33:58.547718&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb52"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> verify_correct_training_flag():</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Verify static output for inference</span></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>    pred <span class="op">=</span> model(X_batch_small, training<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> tqdm(<span class="bu">range</span>(<span class="dv">10</span>)):</span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> tf.reduce_min(tf.cast(pred <span class="op">==</span> model(X_batch_small, training<span class="op">=</span><span class="va">False</span>), tf.int8)) <span class="op">==</span> <span class="dv">1</span></span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Verify at least 99% varying output due to dropout during training</span></span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> tqdm(<span class="bu">range</span>(<span class="dv">10</span>)):</span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> tf.reduce_mean(tf.cast(pred <span class="op">!=</span> model(X_batch_small, training<span class="op">=</span><span class="va">True</span>), tf.float32)) <span class="op">&gt;</span> <span class="fl">0.99</span></span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a>verify_correct_training_flag()</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb53"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;73faad64ac024314af51717507483883&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb54"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;90b983d9960a4c819a7f66ed6deaf170&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
</div>
<section id="verify-no-nan-predictions" class="cell markdown" data-papermill="{&quot;duration&quot;:3.6771e-2,&quot;end_time&quot;:&quot;2023-07-02T11:34:04.151722&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:34:04.114951&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Verify No NaN Predictions</h1>
</section>
<div class="cell code" data-execution_count="40" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:34:04.228496Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:34:04.228128Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:34:13.444000Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:34:13.442975Z&quot;}" data-papermill="{&quot;duration&quot;:9.257248,&quot;end_time&quot;:&quot;2023-07-02T11:34:13.446151&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:34:04.188903&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb55"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Verify No NaN predictions</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> verify_no_nan_predictions():</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> model.predict(</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>        val_dataset <span class="cf">if</span> USE_VAL <span class="cf">else</span> train_dataset,</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>        steps<span class="op">=</span>N_VAL_STEPS_PER_EPOCH <span class="cf">if</span> USE_VAL <span class="cf">else</span> <span class="dv">100</span>,</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>        verbose<span class="op">=</span>VERBOSE,</span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&#39;# NaN Values In Predictions: </span><span class="sc">{</span>np<span class="sc">.</span>isnan(y_pred)<span class="sc">.</span><span class="bu">sum</span>()<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>,<span class="dv">8</span>))</span>
<span id="cb55-12"><a href="#cb55-12" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f&#39;Logit Predictions Initialized Model&#39;</span>)</span>
<span id="cb55-13"><a href="#cb55-13" aria-hidden="true" tabindex="-1"></a>    pd.Series(y_pred.flatten()).plot(kind<span class="op">=</span><span class="st">&#39;hist&#39;</span>, bins<span class="op">=</span><span class="dv">128</span>)</span>
<span id="cb55-14"><a href="#cb55-14" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">&#39;Logits&#39;</span>)</span>
<span id="cb55-15"><a href="#cb55-15" aria-hidden="true" tabindex="-1"></a>    plt.grid()</span>
<span id="cb55-16"><a href="#cb55-16" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb55-17"><a href="#cb55-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb55-18"><a href="#cb55-18" aria-hidden="true" tabindex="-1"></a>verify_no_nan_predictions()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>100/100 - 7s - 7s/epoch - 67ms/step
# NaN Values In Predictions: 0
</code></pre>
</div>
<div class="output display_data">
<p><img src="3616100e4c90bb235ed9b2f99566213e003e6970.png" /></p>
</div>
</div>
<section id="learning-rate-scheduler" class="cell markdown" data-papermill="{&quot;duration&quot;:3.7744e-2,&quot;end_time&quot;:&quot;2023-07-02T11:34:13.521856&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:34:13.484112&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Learning Rate Scheduler</h1>
</section>
<div class="cell code" data-execution_count="41" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:34:13.600629Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:34:13.599585Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:34:13.606884Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:34:13.605926Z&quot;}" data-papermill="{&quot;duration&quot;:4.8796e-2,&quot;end_time&quot;:&quot;2023-07-02T11:34:13.609084&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:34:13.560288&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb57"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> lrfn(current_step, num_warmup_steps, lr_max, num_cycles<span class="op">=</span><span class="fl">0.50</span>, num_training_steps<span class="op">=</span>N_EPOCHS):</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> current_step <span class="op">&lt;</span> num_warmup_steps:</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> WARMUP_METHOD <span class="op">==</span> <span class="st">&#39;log&#39;</span>:</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> lr_max <span class="op">*</span> <span class="fl">0.10</span> <span class="op">**</span> (num_warmup_steps <span class="op">-</span> current_step)</span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> lr_max <span class="op">*</span> <span class="dv">2</span> <span class="op">**</span> <span class="op">-</span>(num_warmup_steps <span class="op">-</span> current_step)</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a>        progress <span class="op">=</span> <span class="bu">float</span>(current_step <span class="op">-</span> num_warmup_steps) <span class="op">/</span> <span class="bu">float</span>(<span class="bu">max</span>(<span class="dv">1</span>, num_training_steps <span class="op">-</span> num_warmup_steps))</span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">max</span>(<span class="fl">0.0</span>, <span class="fl">0.5</span> <span class="op">*</span> (<span class="fl">1.0</span> <span class="op">+</span> math.cos(math.pi <span class="op">*</span> <span class="bu">float</span>(num_cycles) <span class="op">*</span> <span class="fl">2.0</span> <span class="op">*</span> progress))) <span class="op">*</span> lr_max</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="42" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:34:13.689085Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:34:13.688713Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:34:14.530654Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:34:14.529736Z&quot;}" data-papermill="{&quot;duration&quot;:0.885914,&quot;end_time&quot;:&quot;2023-07-02T11:34:14.533559&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:34:13.647645&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb58"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_lr_schedule(lr_schedule, epochs):</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">10</span>))</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>    plt.plot([<span class="va">None</span>] <span class="op">+</span> lr_schedule <span class="op">+</span> [<span class="va">None</span>])</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># X Labels</span></span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> np.arange(<span class="dv">1</span>, epochs <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>    x_axis_labels <span class="op">=</span> [i <span class="cf">if</span> epochs <span class="op">&lt;=</span> <span class="dv">40</span> <span class="kw">or</span> i <span class="op">%</span> <span class="dv">5</span> <span class="op">==</span> <span class="dv">0</span> <span class="kw">or</span> i <span class="op">==</span> <span class="dv">1</span> <span class="cf">else</span> <span class="va">None</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, epochs <span class="op">+</span> <span class="dv">1</span>)]</span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a>    plt.xlim([<span class="dv">1</span>, epochs])</span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a>    plt.xticks(x, x_axis_labels) <span class="co"># set tick step to 1 and let x axis start at 1</span></span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Increase y-limit for better readability</span></span>
<span id="cb58-11"><a href="#cb58-11" aria-hidden="true" tabindex="-1"></a>    plt.ylim([<span class="dv">0</span>, <span class="bu">max</span>(lr_schedule) <span class="op">*</span> <span class="fl">1.1</span>])</span>
<span id="cb58-12"><a href="#cb58-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb58-13"><a href="#cb58-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Title</span></span>
<span id="cb58-14"><a href="#cb58-14" aria-hidden="true" tabindex="-1"></a>    schedule_info <span class="op">=</span> <span class="ss">f&#39;start: </span><span class="sc">{</span>lr_schedule[<span class="dv">0</span>]<span class="sc">:.1E}</span><span class="ss">, max: </span><span class="sc">{</span><span class="bu">max</span>(lr_schedule)<span class="sc">:.1E}</span><span class="ss">, final: </span><span class="sc">{</span>lr_schedule[<span class="op">-</span><span class="dv">1</span>]<span class="sc">:.1E}</span><span class="ss">&#39;</span></span>
<span id="cb58-15"><a href="#cb58-15" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f&#39;Step Learning Rate Schedule, </span><span class="sc">{</span>schedule_info<span class="sc">}</span><span class="ss">&#39;</span>, size<span class="op">=</span><span class="dv">18</span>, pad<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb58-16"><a href="#cb58-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb58-17"><a href="#cb58-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot Learning Rates</span></span>
<span id="cb58-18"><a href="#cb58-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> x, val <span class="kw">in</span> <span class="bu">enumerate</span>(lr_schedule):</span>
<span id="cb58-19"><a href="#cb58-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> epochs <span class="op">&lt;=</span> <span class="dv">40</span> <span class="kw">or</span> x <span class="op">%</span> <span class="dv">5</span> <span class="op">==</span> <span class="dv">0</span> <span class="kw">or</span> x <span class="kw">is</span> epochs <span class="op">-</span> <span class="dv">1</span>:</span>
<span id="cb58-20"><a href="#cb58-20" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> x <span class="op">&lt;</span> <span class="bu">len</span>(lr_schedule) <span class="op">-</span> <span class="dv">1</span>:</span>
<span id="cb58-21"><a href="#cb58-21" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> lr_schedule[x <span class="op">-</span> <span class="dv">1</span>] <span class="op">&lt;</span> val:</span>
<span id="cb58-22"><a href="#cb58-22" aria-hidden="true" tabindex="-1"></a>                    ha <span class="op">=</span> <span class="st">&#39;right&#39;</span></span>
<span id="cb58-23"><a href="#cb58-23" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb58-24"><a href="#cb58-24" aria-hidden="true" tabindex="-1"></a>                    ha <span class="op">=</span> <span class="st">&#39;left&#39;</span></span>
<span id="cb58-25"><a href="#cb58-25" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> x <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb58-26"><a href="#cb58-26" aria-hidden="true" tabindex="-1"></a>                ha <span class="op">=</span> <span class="st">&#39;right&#39;</span></span>
<span id="cb58-27"><a href="#cb58-27" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb58-28"><a href="#cb58-28" aria-hidden="true" tabindex="-1"></a>                ha <span class="op">=</span> <span class="st">&#39;left&#39;</span></span>
<span id="cb58-29"><a href="#cb58-29" aria-hidden="true" tabindex="-1"></a>            plt.plot(x <span class="op">+</span> <span class="dv">1</span>, val, <span class="st">&#39;o&#39;</span>, color<span class="op">=</span><span class="st">&#39;black&#39;</span>)<span class="op">;</span></span>
<span id="cb58-30"><a href="#cb58-30" aria-hidden="true" tabindex="-1"></a>            offset_y <span class="op">=</span> (<span class="bu">max</span>(lr_schedule) <span class="op">-</span> <span class="bu">min</span>(lr_schedule)) <span class="op">*</span> <span class="fl">0.02</span></span>
<span id="cb58-31"><a href="#cb58-31" aria-hidden="true" tabindex="-1"></a>            plt.annotate(<span class="ss">f&#39;</span><span class="sc">{</span>val<span class="sc">:.1E}</span><span class="ss">&#39;</span>, xy<span class="op">=</span>(x <span class="op">+</span> <span class="dv">1</span>, val <span class="op">+</span> offset_y), size<span class="op">=</span><span class="dv">12</span>, ha<span class="op">=</span>ha)</span>
<span id="cb58-32"><a href="#cb58-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb58-33"><a href="#cb58-33" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">&#39;Epoch&#39;</span>, size<span class="op">=</span><span class="dv">16</span>, labelpad<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb58-34"><a href="#cb58-34" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">&#39;Learning Rate&#39;</span>, size<span class="op">=</span><span class="dv">16</span>, labelpad<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb58-35"><a href="#cb58-35" aria-hidden="true" tabindex="-1"></a>    plt.grid()</span>
<span id="cb58-36"><a href="#cb58-36" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb58-37"><a href="#cb58-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-38"><a href="#cb58-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Learning rate for encoder</span></span>
<span id="cb58-39"><a href="#cb58-39" aria-hidden="true" tabindex="-1"></a>LR_SCHEDULE <span class="op">=</span> [lrfn(step, num_warmup_steps<span class="op">=</span>N_WARMUP_EPOCHS, lr_max<span class="op">=</span>LR_MAX, num_cycles<span class="op">=</span><span class="fl">0.50</span>) <span class="cf">for</span> step <span class="kw">in</span> <span class="bu">range</span>(N_EPOCHS)]</span>
<span id="cb58-40"><a href="#cb58-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Learning Rate Schedule</span></span>
<span id="cb58-41"><a href="#cb58-41" aria-hidden="true" tabindex="-1"></a>plot_lr_schedule(LR_SCHEDULE, epochs<span class="op">=</span>N_EPOCHS)</span>
<span id="cb58-42"><a href="#cb58-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Learning Rate Callback</span></span>
<span id="cb58-43"><a href="#cb58-43" aria-hidden="true" tabindex="-1"></a>lr_callback <span class="op">=</span> tf.keras.callbacks.LearningRateScheduler(<span class="kw">lambda</span> step: LR_SCHEDULE[step], verbose<span class="op">=</span><span class="dv">0</span>)</span></code></pre></div>
<div class="output display_data">
<p><img src="99b9413b967f08446ae8a2dbd56da1baa7ac67ea.png" /></p>
</div>
</div>
<section id="weight-decay-callback" class="cell markdown" data-papermill="{&quot;duration&quot;:3.8978e-2,&quot;end_time&quot;:&quot;2023-07-02T11:34:14.612776&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:34:14.573798&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Weight Decay Callback</h1>
</section>
<div class="cell code" data-execution_count="43" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:34:14.694839Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:34:14.694479Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:34:14.700555Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:34:14.699635Z&quot;}" data-papermill="{&quot;duration&quot;:5.1216e-2,&quot;end_time&quot;:&quot;2023-07-02T11:34:14.702691&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:34:14.651475&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb59"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Custom callback to update weight decay with learning rate</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> WeightDecayCallback(tf.keras.callbacks.Callback):</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, wd_ratio<span class="op">=</span>WD_RATIO):</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.step_counter <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.wd_ratio <span class="op">=</span> wd_ratio</span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> on_epoch_begin(<span class="va">self</span>, epoch, logs<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a>        model.optimizer.weight_decay <span class="op">=</span> model.optimizer.learning_rate <span class="op">*</span> <span class="va">self</span>.wd_ratio</span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&#39;learning rate: </span><span class="sc">{</span>model<span class="sc">.</span>optimizer<span class="sc">.</span>learning_rate<span class="sc">.</span>numpy()<span class="sc">:.2e}</span><span class="ss">, weight decay: </span><span class="sc">{</span>model<span class="sc">.</span>optimizer<span class="sc">.</span>weight_decay<span class="sc">.</span>numpy()<span class="sc">:.2e}</span><span class="ss">&#39;</span>)</span></code></pre></div>
</div>
<section id="evaluate-initialized-model" class="cell markdown" data-papermill="{&quot;duration&quot;:3.8896e-2,&quot;end_time&quot;:&quot;2023-07-02T11:34:14.781663&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:34:14.742767&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Evaluate Initialized Model</h1>
</section>
<div class="cell code" data-execution_count="44" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:34:14.860855Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:34:14.860494Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:34:56.277410Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:34:56.276323Z&quot;}" data-papermill="{&quot;duration&quot;:41.4984,&quot;end_time&quot;:&quot;2023-07-02T11:34:56.318989&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:34:14.820589&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb60"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate Initialized Model On Validation Data</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> model.evaluate(</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>    val_dataset <span class="cf">if</span> USE_VAL <span class="cf">else</span> train_dataset,</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>    steps<span class="op">=</span>N_VAL_STEPS_PER_EPOCH <span class="cf">if</span> USE_VAL <span class="cf">else</span> TRAIN_STEPS_PER_EPOCH,</span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span>VERBOSE,</span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>969/969 - 41s - loss: 5.2113 - top1acc: 0.0056 - top5acc: 0.0540 - 41s/epoch - 43ms/step
</code></pre>
</div>
</div>
<section id="baseline" class="cell markdown" data-papermill="{&quot;duration&quot;:4.4168e-2,&quot;end_time&quot;:&quot;2023-07-02T11:34:56.412094&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:34:56.367926&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Baseline</h1>
</section>
<div class="cell code" data-execution_count="45" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:34:56.499670Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:34:56.498727Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:34:56.509783Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:34:56.508373Z&quot;}" data-papermill="{&quot;duration&quot;:5.6578e-2,&quot;end_time&quot;:&quot;2023-07-02T11:34:56.511966&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:34:56.455388&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb62"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co"># baseline accuracy when only pad token is predicted</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> USE_VAL:</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>    baseline_accuracy <span class="op">=</span> np.mean(y_val <span class="op">==</span> PAD_TOKEN)</span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>    baseline_accuracy <span class="op">=</span> np.mean(y_train <span class="op">==</span> PAD_TOKEN)</span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Baseline Accuracy: </span><span class="sc">{</span>baseline_accuracy<span class="sc">:.4f}</span><span class="ss">&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Baseline Accuracy: 0.4100
</code></pre>
</div>
</div>
<section id="train" class="cell markdown" data-papermill="{&quot;duration&quot;:3.9868e-2,&quot;end_time&quot;:&quot;2023-07-02T11:34:56.591346&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:34:56.551478&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Train</h1>
</section>
<div class="cell code" data-execution_count="46" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:34:56.671258Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:34:56.670886Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T11:34:56.967002Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T11:34:56.966035Z&quot;}" data-papermill="{&quot;duration&quot;:0.33862,&quot;end_time&quot;:&quot;2023-07-02T11:34:56.969069&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:34:56.630449&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb64"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>gc.collect()</span></code></pre></div>
<div class="output execute_result" data-execution_count="46">
<pre><code>25963</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="47" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T11:34:57.049375Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T11:34:57.049021Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T14:59:01.214172Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T14:59:01.212946Z&quot;}" data-papermill="{&quot;duration&quot;:12244.208248,&quot;end_time&quot;:&quot;2023-07-02T14:59:01.217198&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T11:34:57.008950&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb66"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> TRAIN_MODEL:</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Clear all models in GPU</span></span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>    tf.keras.backend.clear_session()</span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get new fresh model</span></span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> get_model()</span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sanity Check</span></span>
<span id="cb66-9"><a href="#cb66-9" aria-hidden="true" tabindex="-1"></a>    model.summary()</span>
<span id="cb66-10"><a href="#cb66-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-11"><a href="#cb66-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Actual Training</span></span>
<span id="cb66-12"><a href="#cb66-12" aria-hidden="true" tabindex="-1"></a>    history <span class="op">=</span> model.fit(</span>
<span id="cb66-13"><a href="#cb66-13" aria-hidden="true" tabindex="-1"></a>            x<span class="op">=</span>train_dataset,</span>
<span id="cb66-14"><a href="#cb66-14" aria-hidden="true" tabindex="-1"></a>            steps_per_epoch<span class="op">=</span>TRAIN_STEPS_PER_EPOCH,</span>
<span id="cb66-15"><a href="#cb66-15" aria-hidden="true" tabindex="-1"></a>            epochs<span class="op">=</span>N_EPOCHS,</span>
<span id="cb66-16"><a href="#cb66-16" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Only used for validation data since training data is a generator</span></span>
<span id="cb66-17"><a href="#cb66-17" aria-hidden="true" tabindex="-1"></a>            validation_data<span class="op">=</span>val_dataset <span class="cf">if</span> USE_VAL <span class="cf">else</span> <span class="va">None</span>,</span>
<span id="cb66-18"><a href="#cb66-18" aria-hidden="true" tabindex="-1"></a>            validation_steps<span class="op">=</span>N_VAL_STEPS_PER_EPOCH <span class="cf">if</span> USE_VAL <span class="cf">else</span> <span class="va">None</span>,</span>
<span id="cb66-19"><a href="#cb66-19" aria-hidden="true" tabindex="-1"></a>            callbacks<span class="op">=</span>[</span>
<span id="cb66-20"><a href="#cb66-20" aria-hidden="true" tabindex="-1"></a>                lr_callback,</span>
<span id="cb66-21"><a href="#cb66-21" aria-hidden="true" tabindex="-1"></a>                WeightDecayCallback(),</span>
<span id="cb66-22"><a href="#cb66-22" aria-hidden="true" tabindex="-1"></a>            ],</span>
<span id="cb66-23"><a href="#cb66-23" aria-hidden="true" tabindex="-1"></a>            verbose <span class="op">=</span> VERBOSE,</span>
<span id="cb66-24"><a href="#cb66-24" aria-hidden="true" tabindex="-1"></a>        )</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Model: &quot;model&quot;
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 frames (InputLayer)            [(None, 128, 164)]   0           []                               
                                                                                                  
 masking (Masking)              (None, 128, 164)     0           [&#39;frames[0][0]&#39;]                 
                                                                                                  
 embedding (Embedding)          (None, 128, 384)     259968      [&#39;masking[0][0]&#39;]                
                                                                                                  
 encoder (Encoder)              (None, 128, 256)     2757120     [&#39;embedding[0][0]&#39;,              
                                                                  &#39;frames[0][0]&#39;]                 
                                                                                                  
 phrase (InputLayer)            [(None, 32)]         0           []                               
                                                                                                  
 decoder (Decoder)              (None, 32, 256)      968704      [&#39;encoder[0][0]&#39;,                
                                                                  &#39;phrase[0][0]&#39;]                 
                                                                                                  
 classifier (Sequential)        (None, 32, 62)       15872       [&#39;decoder[0][0]&#39;]                
                                                                                                  
==================================================================================================
Total params: 4,001,664
Trainable params: 4,001,664
Non-trainable params: 0
__________________________________________________________________________________________________
learning rate: 9.77e-07, weight decay: 4.88e-08
Epoch 1/100
969/969 - 162s - loss: 4.6122 - top1acc: 0.0361 - top5acc: 0.1450 - lr: 9.7656e-07 - 162s/epoch - 167ms/step
learning rate: 1.95e-06, weight decay: 9.77e-08
Epoch 2/100
969/969 - 122s - loss: 4.0207 - top1acc: 0.0896 - top5acc: 0.2885 - lr: 1.9531e-06 - 122s/epoch - 126ms/step
learning rate: 3.91e-06, weight decay: 1.95e-07
Epoch 3/100
969/969 - 122s - loss: 3.6777 - top1acc: 0.1410 - top5acc: 0.4200 - lr: 3.9063e-06 - 122s/epoch - 126ms/step
learning rate: 7.81e-06, weight decay: 3.91e-07
Epoch 4/100
969/969 - 122s - loss: 3.4956 - top1acc: 0.1658 - top5acc: 0.4813 - lr: 7.8125e-06 - 122s/epoch - 126ms/step
learning rate: 1.56e-05, weight decay: 7.81e-07
Epoch 5/100
969/969 - 122s - loss: 3.3993 - top1acc: 0.1827 - top5acc: 0.5097 - lr: 1.5625e-05 - 122s/epoch - 126ms/step
learning rate: 3.13e-05, weight decay: 1.56e-06
Epoch 6/100
969/969 - 122s - loss: 3.3298 - top1acc: 0.1978 - top5acc: 0.5319 - lr: 3.1250e-05 - 122s/epoch - 126ms/step
learning rate: 6.25e-05, weight decay: 3.13e-06
Epoch 7/100
969/969 - 122s - loss: 3.2676 - top1acc: 0.2132 - top5acc: 0.5548 - lr: 6.2500e-05 - 122s/epoch - 126ms/step
learning rate: 1.25e-04, weight decay: 6.25e-06
Epoch 8/100
969/969 - 122s - loss: 3.1972 - top1acc: 0.2355 - top5acc: 0.5893 - lr: 1.2500e-04 - 122s/epoch - 126ms/step
learning rate: 2.50e-04, weight decay: 1.25e-05
Epoch 9/100
969/969 - 122s - loss: 3.1032 - top1acc: 0.2700 - top5acc: 0.6449 - lr: 2.5000e-04 - 122s/epoch - 126ms/step
learning rate: 5.00e-04, weight decay: 2.50e-05
Epoch 10/100
969/969 - 122s - loss: 2.9655 - top1acc: 0.3349 - top5acc: 0.7153 - lr: 5.0000e-04 - 122s/epoch - 126ms/step
learning rate: 1.00e-03, weight decay: 5.00e-05
Epoch 11/100
969/969 - 122s - loss: 2.8061 - top1acc: 0.4148 - top5acc: 0.7753 - lr: 0.0010 - 122s/epoch - 126ms/step
learning rate: 1.00e-03, weight decay: 5.00e-05
Epoch 12/100
969/969 - 122s - loss: 2.6406 - top1acc: 0.4967 - top5acc: 0.8215 - lr: 9.9970e-04 - 122s/epoch - 126ms/step
learning rate: 9.99e-04, weight decay: 4.99e-05
Epoch 13/100
969/969 - 122s - loss: 2.5450 - top1acc: 0.5440 - top5acc: 0.8424 - lr: 9.9878e-04 - 122s/epoch - 126ms/step
learning rate: 9.97e-04, weight decay: 4.99e-05
Epoch 14/100
969/969 - 122s - loss: 2.4808 - top1acc: 0.5747 - top5acc: 0.8553 - lr: 9.9726e-04 - 122s/epoch - 126ms/step
learning rate: 9.95e-04, weight decay: 4.98e-05
Epoch 15/100
969/969 - 122s - loss: 2.4287 - top1acc: 0.5987 - top5acc: 0.8650 - lr: 9.9513e-04 - 122s/epoch - 126ms/step
learning rate: 9.92e-04, weight decay: 4.96e-05
Epoch 16/100
969/969 - 122s - loss: 2.3917 - top1acc: 0.6167 - top5acc: 0.8707 - lr: 9.9240e-04 - 122s/epoch - 126ms/step
learning rate: 9.89e-04, weight decay: 4.95e-05
Epoch 17/100
969/969 - 122s - loss: 2.3610 - top1acc: 0.6308 - top5acc: 0.8759 - lr: 9.8907e-04 - 122s/epoch - 126ms/step
learning rate: 9.85e-04, weight decay: 4.93e-05
Epoch 18/100
969/969 - 122s - loss: 2.3355 - top1acc: 0.6420 - top5acc: 0.8802 - lr: 9.8515e-04 - 122s/epoch - 126ms/step
learning rate: 9.81e-04, weight decay: 4.90e-05
Epoch 19/100
969/969 - 122s - loss: 2.3175 - top1acc: 0.6501 - top5acc: 0.8829 - lr: 9.8063e-04 - 122s/epoch - 126ms/step
learning rate: 9.76e-04, weight decay: 4.88e-05
Epoch 20/100
969/969 - 122s - loss: 2.2995 - top1acc: 0.6581 - top5acc: 0.8864 - lr: 9.7553e-04 - 122s/epoch - 126ms/step
learning rate: 9.70e-04, weight decay: 4.85e-05
Epoch 21/100
969/969 - 122s - loss: 2.2807 - top1acc: 0.6671 - top5acc: 0.8897 - lr: 9.6985e-04 - 122s/epoch - 126ms/step
learning rate: 9.64e-04, weight decay: 4.82e-05
Epoch 22/100
969/969 - 122s - loss: 2.2646 - top1acc: 0.6745 - top5acc: 0.8928 - lr: 9.6359e-04 - 122s/epoch - 126ms/step
learning rate: 9.57e-04, weight decay: 4.78e-05
Epoch 23/100
969/969 - 122s - loss: 2.2579 - top1acc: 0.6769 - top5acc: 0.8932 - lr: 9.5677e-04 - 122s/epoch - 126ms/step
learning rate: 9.49e-04, weight decay: 4.75e-05
Epoch 24/100
969/969 - 122s - loss: 2.2454 - top1acc: 0.6825 - top5acc: 0.8952 - lr: 9.4940e-04 - 122s/epoch - 126ms/step
learning rate: 9.41e-04, weight decay: 4.71e-05
Epoch 25/100
969/969 - 122s - loss: 2.2367 - top1acc: 0.6871 - top5acc: 0.8969 - lr: 9.4147e-04 - 122s/epoch - 125ms/step
learning rate: 9.33e-04, weight decay: 4.67e-05
Epoch 26/100
969/969 - 122s - loss: 2.2255 - top1acc: 0.6918 - top5acc: 0.8989 - lr: 9.3301e-04 - 122s/epoch - 125ms/step
learning rate: 9.24e-04, weight decay: 4.62e-05
Epoch 27/100
969/969 - 121s - loss: 2.2125 - top1acc: 0.6976 - top5acc: 0.9014 - lr: 9.2402e-04 - 121s/epoch - 125ms/step
learning rate: 9.15e-04, weight decay: 4.57e-05
Epoch 28/100
969/969 - 122s - loss: 2.2068 - top1acc: 0.7006 - top5acc: 0.9022 - lr: 9.1452e-04 - 122s/epoch - 125ms/step
learning rate: 9.05e-04, weight decay: 4.52e-05
Epoch 29/100
969/969 - 121s - loss: 2.1960 - top1acc: 0.7052 - top5acc: 0.9042 - lr: 9.0451e-04 - 121s/epoch - 125ms/step
learning rate: 8.94e-04, weight decay: 4.47e-05
Epoch 30/100
969/969 - 122s - loss: 2.1914 - top1acc: 0.7075 - top5acc: 0.9039 - lr: 8.9401e-04 - 122s/epoch - 126ms/step
learning rate: 8.83e-04, weight decay: 4.42e-05
Epoch 31/100
969/969 - 122s - loss: 2.1787 - top1acc: 0.7135 - top5acc: 0.9071 - lr: 8.8302e-04 - 122s/epoch - 125ms/step
learning rate: 8.72e-04, weight decay: 4.36e-05
Epoch 32/100
969/969 - 122s - loss: 2.1743 - top1acc: 0.7150 - top5acc: 0.9072 - lr: 8.7157e-04 - 122s/epoch - 125ms/step
learning rate: 8.60e-04, weight decay: 4.30e-05
Epoch 33/100
969/969 - 122s - loss: 2.1678 - top1acc: 0.7185 - top5acc: 0.9082 - lr: 8.5967e-04 - 122s/epoch - 125ms/step
learning rate: 8.47e-04, weight decay: 4.24e-05
Epoch 34/100
969/969 - 121s - loss: 2.1615 - top1acc: 0.7213 - top5acc: 0.9089 - lr: 8.4733e-04 - 121s/epoch - 125ms/step
learning rate: 8.35e-04, weight decay: 4.17e-05
Epoch 35/100
969/969 - 122s - loss: 2.1588 - top1acc: 0.7221 - top5acc: 0.9097 - lr: 8.3457e-04 - 122s/epoch - 125ms/step
learning rate: 8.21e-04, weight decay: 4.11e-05
Epoch 36/100
969/969 - 121s - loss: 2.1473 - top1acc: 0.7277 - top5acc: 0.9116 - lr: 8.2139e-04 - 121s/epoch - 125ms/step
learning rate: 8.08e-04, weight decay: 4.04e-05
Epoch 37/100
969/969 - 121s - loss: 2.1449 - top1acc: 0.7288 - top5acc: 0.9120 - lr: 8.0783e-04 - 121s/epoch - 125ms/step
learning rate: 7.94e-04, weight decay: 3.97e-05
Epoch 38/100
969/969 - 121s - loss: 2.1367 - top1acc: 0.7324 - top5acc: 0.9135 - lr: 7.9389e-04 - 121s/epoch - 125ms/step
learning rate: 7.80e-04, weight decay: 3.90e-05
Epoch 39/100
969/969 - 121s - loss: 2.1328 - top1acc: 0.7342 - top5acc: 0.9144 - lr: 7.7960e-04 - 121s/epoch - 125ms/step
learning rate: 7.65e-04, weight decay: 3.82e-05
Epoch 40/100
969/969 - 122s - loss: 2.1275 - top1acc: 0.7365 - top5acc: 0.9152 - lr: 7.6496e-04 - 122s/epoch - 125ms/step
learning rate: 7.50e-04, weight decay: 3.75e-05
Epoch 41/100
969/969 - 121s - loss: 2.1243 - top1acc: 0.7383 - top5acc: 0.9157 - lr: 7.5000e-04 - 121s/epoch - 125ms/step
learning rate: 7.35e-04, weight decay: 3.67e-05
Epoch 42/100
969/969 - 122s - loss: 2.1191 - top1acc: 0.7403 - top5acc: 0.9166 - lr: 7.3474e-04 - 122s/epoch - 125ms/step
learning rate: 7.19e-04, weight decay: 3.60e-05
Epoch 43/100
969/969 - 122s - loss: 2.1122 - top1acc: 0.7435 - top5acc: 0.9180 - lr: 7.1919e-04 - 122s/epoch - 125ms/step
learning rate: 7.03e-04, weight decay: 3.52e-05
Epoch 44/100
969/969 - 121s - loss: 2.1114 - top1acc: 0.7440 - top5acc: 0.9174 - lr: 7.0337e-04 - 121s/epoch - 125ms/step
learning rate: 6.87e-04, weight decay: 3.44e-05
Epoch 45/100
969/969 - 121s - loss: 2.1056 - top1acc: 0.7463 - top5acc: 0.9192 - lr: 6.8730e-04 - 121s/epoch - 125ms/step
learning rate: 6.71e-04, weight decay: 3.36e-05
Epoch 46/100
969/969 - 122s - loss: 2.0996 - top1acc: 0.7496 - top5acc: 0.9196 - lr: 6.7101e-04 - 122s/epoch - 126ms/step
learning rate: 6.55e-04, weight decay: 3.27e-05
Epoch 47/100
969/969 - 122s - loss: 2.0943 - top1acc: 0.7517 - top5acc: 0.9206 - lr: 6.5451e-04 - 122s/epoch - 125ms/step
learning rate: 6.38e-04, weight decay: 3.19e-05
Epoch 48/100
969/969 - 121s - loss: 2.0912 - top1acc: 0.7529 - top5acc: 0.9213 - lr: 6.3782e-04 - 121s/epoch - 125ms/step
learning rate: 6.21e-04, weight decay: 3.10e-05
Epoch 49/100
969/969 - 121s - loss: 2.0864 - top1acc: 0.7549 - top5acc: 0.9215 - lr: 6.2096e-04 - 121s/epoch - 125ms/step
learning rate: 6.04e-04, weight decay: 3.02e-05
Epoch 50/100
969/969 - 121s - loss: 2.0854 - top1acc: 0.7560 - top5acc: 0.9220 - lr: 6.0396e-04 - 121s/epoch - 125ms/step
learning rate: 5.87e-04, weight decay: 2.93e-05
Epoch 51/100
969/969 - 121s - loss: 2.0793 - top1acc: 0.7582 - top5acc: 0.9235 - lr: 5.8682e-04 - 121s/epoch - 125ms/step
learning rate: 5.70e-04, weight decay: 2.85e-05
Epoch 52/100
969/969 - 121s - loss: 2.0775 - top1acc: 0.7590 - top5acc: 0.9233 - lr: 5.6959e-04 - 121s/epoch - 125ms/step
learning rate: 5.52e-04, weight decay: 2.76e-05
Epoch 53/100
969/969 - 121s - loss: 2.0662 - top1acc: 0.7643 - top5acc: 0.9258 - lr: 5.5226e-04 - 121s/epoch - 125ms/step
learning rate: 5.35e-04, weight decay: 2.67e-05
Epoch 54/100
969/969 - 121s - loss: 2.0622 - top1acc: 0.7657 - top5acc: 0.9263 - lr: 5.3488e-04 - 121s/epoch - 125ms/step
learning rate: 5.17e-04, weight decay: 2.59e-05
Epoch 55/100
969/969 - 121s - loss: 2.0592 - top1acc: 0.7674 - top5acc: 0.9268 - lr: 5.1745e-04 - 121s/epoch - 125ms/step
learning rate: 5.00e-04, weight decay: 2.50e-05
Epoch 56/100
969/969 - 121s - loss: 2.0576 - top1acc: 0.7682 - top5acc: 0.9267 - lr: 5.0000e-04 - 121s/epoch - 125ms/step
learning rate: 4.83e-04, weight decay: 2.41e-05
Epoch 57/100
969/969 - 121s - loss: 2.0574 - top1acc: 0.7680 - top5acc: 0.9269 - lr: 4.8255e-04 - 121s/epoch - 125ms/step
learning rate: 4.65e-04, weight decay: 2.33e-05
Epoch 58/100
969/969 - 122s - loss: 2.0485 - top1acc: 0.7721 - top5acc: 0.9284 - lr: 4.6512e-04 - 122s/epoch - 125ms/step
learning rate: 4.48e-04, weight decay: 2.24e-05
Epoch 59/100
969/969 - 122s - loss: 2.0460 - top1acc: 0.7733 - top5acc: 0.9280 - lr: 4.4774e-04 - 122s/epoch - 125ms/step
learning rate: 4.30e-04, weight decay: 2.15e-05
Epoch 60/100
969/969 - 121s - loss: 2.0406 - top1acc: 0.7759 - top5acc: 0.9296 - lr: 4.3041e-04 - 121s/epoch - 125ms/step
learning rate: 4.13e-04, weight decay: 2.07e-05
Epoch 61/100
969/969 - 121s - loss: 2.0339 - top1acc: 0.7784 - top5acc: 0.9309 - lr: 4.1318e-04 - 121s/epoch - 125ms/step
learning rate: 3.96e-04, weight decay: 1.98e-05
Epoch 62/100
969/969 - 121s - loss: 2.0326 - top1acc: 0.7794 - top5acc: 0.9310 - lr: 3.9604e-04 - 121s/epoch - 125ms/step
learning rate: 3.79e-04, weight decay: 1.90e-05
Epoch 63/100
969/969 - 121s - loss: 2.0288 - top1acc: 0.7811 - top5acc: 0.9317 - lr: 3.7904e-04 - 121s/epoch - 125ms/step
learning rate: 3.62e-04, weight decay: 1.81e-05
Epoch 64/100
969/969 - 121s - loss: 2.0246 - top1acc: 0.7830 - top5acc: 0.9322 - lr: 3.6218e-04 - 121s/epoch - 125ms/step
learning rate: 3.45e-04, weight decay: 1.73e-05
Epoch 65/100
969/969 - 122s - loss: 2.0202 - top1acc: 0.7852 - top5acc: 0.9332 - lr: 3.4549e-04 - 122s/epoch - 125ms/step
learning rate: 3.29e-04, weight decay: 1.64e-05
Epoch 66/100
969/969 - 121s - loss: 2.0178 - top1acc: 0.7861 - top5acc: 0.9335 - lr: 3.2899e-04 - 121s/epoch - 125ms/step
learning rate: 3.13e-04, weight decay: 1.56e-05
Epoch 67/100
969/969 - 121s - loss: 2.0151 - top1acc: 0.7878 - top5acc: 0.9340 - lr: 3.1270e-04 - 121s/epoch - 125ms/step
learning rate: 2.97e-04, weight decay: 1.48e-05
Epoch 68/100
969/969 - 121s - loss: 2.0110 - top1acc: 0.7893 - top5acc: 0.9346 - lr: 2.9663e-04 - 121s/epoch - 125ms/step
learning rate: 2.81e-04, weight decay: 1.40e-05
Epoch 69/100
969/969 - 122s - loss: 2.0084 - top1acc: 0.7905 - top5acc: 0.9348 - lr: 2.8081e-04 - 122s/epoch - 126ms/step
learning rate: 2.65e-04, weight decay: 1.33e-05
Epoch 70/100
969/969 - 121s - loss: 2.0054 - top1acc: 0.7921 - top5acc: 0.9353 - lr: 2.6526e-04 - 121s/epoch - 125ms/step
learning rate: 2.50e-04, weight decay: 1.25e-05
Epoch 71/100
969/969 - 121s - loss: 2.0022 - top1acc: 0.7935 - top5acc: 0.9361 - lr: 2.5000e-04 - 121s/epoch - 125ms/step
learning rate: 2.35e-04, weight decay: 1.18e-05
Epoch 72/100
969/969 - 121s - loss: 1.9969 - top1acc: 0.7956 - top5acc: 0.9369 - lr: 2.3504e-04 - 121s/epoch - 125ms/step
learning rate: 2.20e-04, weight decay: 1.10e-05
Epoch 73/100
969/969 - 121s - loss: 1.9977 - top1acc: 0.7953 - top5acc: 0.9367 - lr: 2.2040e-04 - 121s/epoch - 125ms/step
learning rate: 2.06e-04, weight decay: 1.03e-05
Epoch 74/100
969/969 - 121s - loss: 1.9919 - top1acc: 0.7980 - top5acc: 0.9376 - lr: 2.0611e-04 - 121s/epoch - 125ms/step
learning rate: 1.92e-04, weight decay: 9.61e-06
Epoch 75/100
969/969 - 121s - loss: 1.9895 - top1acc: 0.7993 - top5acc: 0.9380 - lr: 1.9217e-04 - 121s/epoch - 125ms/step
learning rate: 1.79e-04, weight decay: 8.93e-06
Epoch 76/100
969/969 - 121s - loss: 1.9856 - top1acc: 0.8010 - top5acc: 0.9389 - lr: 1.7861e-04 - 121s/epoch - 125ms/step
learning rate: 1.65e-04, weight decay: 8.27e-06
Epoch 77/100
969/969 - 122s - loss: 1.9875 - top1acc: 0.8000 - top5acc: 0.9383 - lr: 1.6543e-04 - 122s/epoch - 125ms/step
learning rate: 1.53e-04, weight decay: 7.63e-06
Epoch 78/100
969/969 - 121s - loss: 1.9811 - top1acc: 0.8033 - top5acc: 0.9390 - lr: 1.5267e-04 - 121s/epoch - 125ms/step
learning rate: 1.40e-04, weight decay: 7.02e-06
Epoch 79/100
969/969 - 121s - loss: 1.9761 - top1acc: 0.8056 - top5acc: 0.9401 - lr: 1.4033e-04 - 121s/epoch - 125ms/step
learning rate: 1.28e-04, weight decay: 6.42e-06
Epoch 80/100
969/969 - 122s - loss: 1.9772 - top1acc: 0.8052 - top5acc: 0.9399 - lr: 1.2843e-04 - 122s/epoch - 126ms/step
learning rate: 1.17e-04, weight decay: 5.85e-06
Epoch 81/100
969/969 - 122s - loss: 1.9758 - top1acc: 0.8056 - top5acc: 0.9397 - lr: 1.1698e-04 - 122s/epoch - 126ms/step
learning rate: 1.06e-04, weight decay: 5.30e-06
Epoch 82/100
969/969 - 121s - loss: 1.9718 - top1acc: 0.8076 - top5acc: 0.9410 - lr: 1.0599e-04 - 121s/epoch - 125ms/step
learning rate: 9.55e-05, weight decay: 4.77e-06
Epoch 83/100
969/969 - 121s - loss: 1.9726 - top1acc: 0.8068 - top5acc: 0.9403 - lr: 9.5492e-05 - 121s/epoch - 125ms/step
learning rate: 8.55e-05, weight decay: 4.27e-06
Epoch 84/100
969/969 - 121s - loss: 1.9699 - top1acc: 0.8079 - top5acc: 0.9411 - lr: 8.5481e-05 - 121s/epoch - 125ms/step
learning rate: 7.60e-05, weight decay: 3.80e-06
Epoch 85/100
969/969 - 121s - loss: 1.9629 - top1acc: 0.8112 - top5acc: 0.9423 - lr: 7.5976e-05 - 121s/epoch - 125ms/step
learning rate: 6.70e-05, weight decay: 3.35e-06
Epoch 86/100
969/969 - 121s - loss: 1.9621 - top1acc: 0.8120 - top5acc: 0.9421 - lr: 6.6987e-05 - 121s/epoch - 125ms/step
learning rate: 5.85e-05, weight decay: 2.93e-06
Epoch 87/100
969/969 - 122s - loss: 1.9612 - top1acc: 0.8123 - top5acc: 0.9422 - lr: 5.8526e-05 - 122s/epoch - 125ms/step
learning rate: 5.06e-05, weight decay: 2.53e-06
Epoch 88/100
969/969 - 122s - loss: 1.9624 - top1acc: 0.8122 - top5acc: 0.9421 - lr: 5.0603e-05 - 122s/epoch - 126ms/step
learning rate: 4.32e-05, weight decay: 2.16e-06
Epoch 89/100
969/969 - 121s - loss: 1.9623 - top1acc: 0.8119 - top5acc: 0.9423 - lr: 4.3227e-05 - 121s/epoch - 125ms/step
learning rate: 3.64e-05, weight decay: 1.82e-06
Epoch 90/100
969/969 - 121s - loss: 1.9598 - top1acc: 0.8131 - top5acc: 0.9426 - lr: 3.6408e-05 - 121s/epoch - 125ms/step
learning rate: 3.02e-05, weight decay: 1.51e-06
Epoch 91/100
969/969 - 121s - loss: 1.9591 - top1acc: 0.8136 - top5acc: 0.9429 - lr: 3.0154e-05 - 121s/epoch - 125ms/step
learning rate: 2.45e-05, weight decay: 1.22e-06
Epoch 92/100
969/969 - 122s - loss: 1.9619 - top1acc: 0.8122 - top5acc: 0.9421 - lr: 2.4472e-05 - 122s/epoch - 126ms/step
learning rate: 1.94e-05, weight decay: 9.68e-07
Epoch 93/100
969/969 - 121s - loss: 1.9598 - top1acc: 0.8131 - top5acc: 0.9422 - lr: 1.9369e-05 - 121s/epoch - 125ms/step
learning rate: 1.49e-05, weight decay: 7.43e-07
Epoch 94/100
969/969 - 121s - loss: 1.9587 - top1acc: 0.8134 - top5acc: 0.9426 - lr: 1.4852e-05 - 121s/epoch - 125ms/step
learning rate: 1.09e-05, weight decay: 5.46e-07
Epoch 95/100
969/969 - 121s - loss: 1.9585 - top1acc: 0.8136 - top5acc: 0.9425 - lr: 1.0926e-05 - 121s/epoch - 125ms/step
learning rate: 7.60e-06, weight decay: 3.80e-07
Epoch 96/100
969/969 - 122s - loss: 1.9566 - top1acc: 0.8147 - top5acc: 0.9427 - lr: 7.5961e-06 - 122s/epoch - 125ms/step
learning rate: 4.87e-06, weight decay: 2.43e-07
Epoch 97/100
969/969 - 122s - loss: 1.9557 - top1acc: 0.8151 - top5acc: 0.9430 - lr: 4.8660e-06 - 122s/epoch - 126ms/step
learning rate: 2.74e-06, weight decay: 1.37e-07
Epoch 98/100
969/969 - 121s - loss: 1.9566 - top1acc: 0.8143 - top5acc: 0.9427 - lr: 2.7391e-06 - 121s/epoch - 125ms/step
learning rate: 1.22e-06, weight decay: 6.09e-08
Epoch 99/100
969/969 - 121s - loss: 1.9548 - top1acc: 0.8153 - top5acc: 0.9432 - lr: 1.2180e-06 - 121s/epoch - 125ms/step
learning rate: 3.05e-07, weight decay: 1.52e-08
Epoch 100/100
969/969 - 121s - loss: 1.9529 - top1acc: 0.8162 - top5acc: 0.9439 - lr: 3.0459e-07 - 121s/epoch - 125ms/step
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="48" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T14:59:01.340192Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T14:59:01.339775Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T14:59:01.345065Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T14:59:01.344095Z&quot;}" data-papermill="{&quot;duration&quot;:6.9569e-2,&quot;end_time&quot;:&quot;2023-07-02T14:59:01.347383&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T14:59:01.277814&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb68"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load Weights</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> LOAD_WEIGHTS:</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>    model.load_weights(<span class="st">&#39;/kaggle/input/aslfr-training-python37/model.h5&#39;</span>)</span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&#39;Successfully Loaded Pretrained Weights&#39;</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="49" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T14:59:01.473460Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T14:59:01.473099Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T14:59:01.614139Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T14:59:01.613115Z&quot;}" data-papermill="{&quot;duration&quot;:0.206194,&quot;end_time&quot;:&quot;2023-07-02T14:59:01.616525&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T14:59:01.410331&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb69"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Save Model Weights</span></span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>model.save_weights(<span class="st">&#39;model.h5&#39;</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="50" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T14:59:01.731652Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T14:59:01.731309Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T14:59:42.975944Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T14:59:42.974845Z&quot;}" data-papermill="{&quot;duration&quot;:41.357991,&quot;end_time&quot;:&quot;2023-07-02T14:59:43.031109&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T14:59:01.673118&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb70"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Verify Model is Loaded Correctly</span></span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>model.evaluate(</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>    val_dataset <span class="cf">if</span> USE_VAL <span class="cf">else</span> train_dataset,</span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a>    steps<span class="op">=</span>N_VAL_STEPS_PER_EPOCH <span class="cf">if</span> USE_VAL <span class="cf">else</span> TRAIN_STEPS_PER_EPOCH,</span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span>BATCH_SIZE,</span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span>VERBOSE,</span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>969/969 - 41s - loss: 1.8608 - top1acc: 0.8571 - top5acc: 0.9561 - 41s/epoch - 43ms/step
</code></pre>
</div>
<div class="output execute_result" data-execution_count="50">
<pre><code>[1.8608417510986328, 0.8570798635482788, 0.9560850262641907]</code></pre>
</div>
</div>
<section id="levenshtein-distance" class="cell markdown" data-papermill="{&quot;duration&quot;:5.6044e-2,&quot;end_time&quot;:&quot;2023-07-02T14:59:43.142922&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T14:59:43.086878&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Levenshtein Distance</h1>
</section>
<div class="cell code" data-execution_count="51" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T14:59:43.259015Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T14:59:43.257980Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T14:59:43.264399Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T14:59:43.263383Z&quot;}" data-papermill="{&quot;duration&quot;:6.6802e-2,&quot;end_time&quot;:&quot;2023-07-02T14:59:43.266519&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T14:59:43.199717&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb73"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Output Predictions to string</span></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> outputs2phrase(outputs):</span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> outputs.ndim <span class="op">==</span> <span class="dv">2</span>:</span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> np.argmax(outputs, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb73-6"><a href="#cb73-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">&#39;&#39;</span>.join([ORD2CHAR.get(s, <span class="st">&#39;&#39;</span>) <span class="cf">for</span> s <span class="kw">in</span> outputs])</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="52" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T14:59:43.382911Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T14:59:43.381914Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T14:59:43.390755Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T14:59:43.389845Z&quot;}" data-papermill="{&quot;duration&quot;:6.8395e-2,&quot;end_time&quot;:&quot;2023-07-02T14:59:43.392955&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T14:59:43.324560&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb74"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="at">@tf.function</span>()</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> predict_phrase(frames):</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add Batch Dimension</span></span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a>    frames <span class="op">=</span> tf.expand_dims(frames, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Start Phrase</span></span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a>    phrase <span class="op">=</span> tf.fill([<span class="dv">1</span>,MAX_PHRASE_LENGTH], PAD_TOKEN)</span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-8"><a href="#cb74-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx <span class="kw">in</span> tf.<span class="bu">range</span>(MAX_PHRASE_LENGTH):</span>
<span id="cb74-9"><a href="#cb74-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Cast phrase to int8</span></span>
<span id="cb74-10"><a href="#cb74-10" aria-hidden="true" tabindex="-1"></a>        phrase <span class="op">=</span> tf.cast(phrase, tf.int8)</span>
<span id="cb74-11"><a href="#cb74-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Predict Next Token</span></span>
<span id="cb74-12"><a href="#cb74-12" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model({</span>
<span id="cb74-13"><a href="#cb74-13" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;frames&#39;</span>: frames,</span>
<span id="cb74-14"><a href="#cb74-14" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;phrase&#39;</span>: phrase,</span>
<span id="cb74-15"><a href="#cb74-15" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb74-16"><a href="#cb74-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-17"><a href="#cb74-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add predicted token to input phrase</span></span>
<span id="cb74-18"><a href="#cb74-18" aria-hidden="true" tabindex="-1"></a>        phrase <span class="op">=</span> tf.cast(phrase, tf.int32)</span>
<span id="cb74-19"><a href="#cb74-19" aria-hidden="true" tabindex="-1"></a>        phrase <span class="op">=</span> tf.where(</span>
<span id="cb74-20"><a href="#cb74-20" aria-hidden="true" tabindex="-1"></a>            tf.<span class="bu">range</span>(MAX_PHRASE_LENGTH) <span class="op">&lt;</span> idx <span class="op">+</span> <span class="dv">1</span>,</span>
<span id="cb74-21"><a href="#cb74-21" aria-hidden="true" tabindex="-1"></a>            tf.argmax(outputs, axis<span class="op">=</span><span class="dv">2</span>, output_type<span class="op">=</span>tf.int32),</span>
<span id="cb74-22"><a href="#cb74-22" aria-hidden="true" tabindex="-1"></a>            phrase,</span>
<span id="cb74-23"><a href="#cb74-23" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb74-24"><a href="#cb74-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-25"><a href="#cb74-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Squeeze outputs</span></span>
<span id="cb74-26"><a href="#cb74-26" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> tf.squeeze(phrase, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb74-27"><a href="#cb74-27" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> tf.one_hot(outputs, N_UNIQUE_CHARACTERS)</span>
<span id="cb74-28"><a href="#cb74-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-29"><a href="#cb74-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return a dictionary with the output tensor</span></span>
<span id="cb74-30"><a href="#cb74-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> outputs</span>
<span id="cb74-31"><a href="#cb74-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-32"><a href="#cb74-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return a dictionary with the output tensor</span></span>
<span id="cb74-33"><a href="#cb74-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> outputs</span></code></pre></div>
</div>
<section id="levenstein-distance-train" class="cell markdown" data-papermill="{&quot;duration&quot;:5.6358e-2,&quot;end_time&quot;:&quot;2023-07-02T14:59:43.504839&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T14:59:43.448481&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Levenstein Distance Train</h1>
</section>
<div class="cell code" data-execution_count="53" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T14:59:43.623093Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T14:59:43.622699Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T14:59:43.631624Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T14:59:43.630718Z&quot;}" data-papermill="{&quot;duration&quot;:7.1676e-2,&quot;end_time&quot;:&quot;2023-07-02T14:59:43.633777&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T14:59:43.562101&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb75"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute Levenstein Distances</span></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_ld_train():</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>    N <span class="op">=</span> <span class="dv">100</span> <span class="cf">if</span> IS_INTERACTIVE <span class="cf">else</span> <span class="dv">1000</span></span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a>    LD_TRAIN <span class="op">=</span> []</span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx, (frames, phrase_true) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">zip</span>(tqdm(X_train, total<span class="op">=</span>N), y_train)):</span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Predict Phrase and Convert to String</span></span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a>        phrase_pred <span class="op">=</span> predict_phrase(frames).numpy()</span>
<span id="cb75-8"><a href="#cb75-8" aria-hidden="true" tabindex="-1"></a>        phrase_pred <span class="op">=</span> outputs2phrase(phrase_pred)</span>
<span id="cb75-9"><a href="#cb75-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># True Phrase Ordinal to String</span></span>
<span id="cb75-10"><a href="#cb75-10" aria-hidden="true" tabindex="-1"></a>        phrase_true <span class="op">=</span> outputs2phrase(phrase_true)</span>
<span id="cb75-11"><a href="#cb75-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add Levenstein Distance</span></span>
<span id="cb75-12"><a href="#cb75-12" aria-hidden="true" tabindex="-1"></a>        LD_TRAIN.append({</span>
<span id="cb75-13"><a href="#cb75-13" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;phrase_true&#39;</span>: phrase_true,</span>
<span id="cb75-14"><a href="#cb75-14" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;phrase_pred&#39;</span>: phrase_pred,</span>
<span id="cb75-15"><a href="#cb75-15" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;levenshtein_distance&#39;</span>: levenshtein(phrase_pred, phrase_true),</span>
<span id="cb75-16"><a href="#cb75-16" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb75-17"><a href="#cb75-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Take subset in interactive mode</span></span>
<span id="cb75-18"><a href="#cb75-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idx <span class="op">==</span> N:</span>
<span id="cb75-19"><a href="#cb75-19" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb75-20"><a href="#cb75-20" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb75-21"><a href="#cb75-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert to DataFrame</span></span>
<span id="cb75-22"><a href="#cb75-22" aria-hidden="true" tabindex="-1"></a>    LD_TRAIN_DF <span class="op">=</span> pd.DataFrame(LD_TRAIN)</span>
<span id="cb75-23"><a href="#cb75-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb75-24"><a href="#cb75-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> LD_TRAIN_DF</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="54" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T14:59:43.751663Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T14:59:43.750977Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T15:01:50.106368Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T15:01:50.105419Z&quot;}" data-papermill="{&quot;duration&quot;:126.418133,&quot;end_time&quot;:&quot;2023-07-02T15:01:50.108598&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T14:59:43.690465&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb76"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>LD_TRAIN_DF <span class="op">=</span> get_ld_train()</span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Display Errors</span></span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a>display(LD_TRAIN_DF.head(<span class="dv">30</span>))</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb77"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;cdab5ab7bd524d8883eee5eb249d4a84&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>phrase_true</th>
      <th>phrase_pred</th>
      <th>levenshtein_distance</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3 creekhouse</td>
      <td>3 creek housese.de</td>
      <td>6</td>
    </tr>
    <tr>
      <th>1</th>
      <td>scales/kuhaylah</td>
      <td>scales/kuhaylaaa</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>hentaihubs.com</td>
      <td>hentaihubs.com.com</td>
      <td>4</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1383 william lanier</td>
      <td>1383 william lanier</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>988 franklin lane</td>
      <td>988 franklin lane lanee</td>
      <td>6</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6920 northeast 661st road</td>
      <td>6920 northeast 661st roadd</td>
      <td>1</td>
    </tr>
    <tr>
      <th>6</th>
      <td>www.freem.ne.jp</td>
      <td>www.freem.me.jp.jp</td>
      <td>4</td>
    </tr>
    <tr>
      <th>7</th>
      <td>https://jsi.is/hukuoka</td>
      <td>https://jsi.is/htkuoka</td>
      <td>1</td>
    </tr>
    <tr>
      <th>8</th>
      <td>239613 stolze street</td>
      <td>23961a3 stolze streets stre</td>
      <td>7</td>
    </tr>
    <tr>
      <th>9</th>
      <td>242-197-6202</td>
      <td>217-686-0202</td>
      <td>6</td>
    </tr>
    <tr>
      <th>10</th>
      <td>271097 bayshore boulevard</td>
      <td>271097 bayhore boulevard</td>
      <td>1</td>
    </tr>
    <tr>
      <th>11</th>
      <td>federico pearson</td>
      <td>federico pearonon</td>
      <td>2</td>
    </tr>
    <tr>
      <th>12</th>
      <td>/carpina/hope_&amp;_faith/litle</td>
      <td>/carpina/hope_z_fith/litlee</td>
      <td>3</td>
    </tr>
    <tr>
      <th>13</th>
      <td>dine-in/code/</td>
      <td>dine-cin/code/code/code//</td>
      <td>12</td>
    </tr>
    <tr>
      <th>14</th>
      <td>+264-97-568-217-145</td>
      <td>+264-97-5482-2745</td>
      <td>5</td>
    </tr>
    <tr>
      <th>15</th>
      <td>+51-2721-208-63</td>
      <td>+51-271-208-6363</td>
      <td>3</td>
    </tr>
    <tr>
      <th>16</th>
      <td>wildberries_ru</td>
      <td>wilders-murces-lu</td>
      <td>8</td>
    </tr>
    <tr>
      <th>17</th>
      <td>leona owens</td>
      <td>leona owenslens</td>
      <td>4</td>
    </tr>
    <tr>
      <th>18</th>
      <td>+220-557-859-04</td>
      <td>+220-557-859-0404</td>
      <td>2</td>
    </tr>
    <tr>
      <th>19</th>
      <td>kati castro</td>
      <td>kati castro</td>
      <td>0</td>
    </tr>
    <tr>
      <th>20</th>
      <td>5566 hellertown road</td>
      <td>56 cll rock</td>
      <td>12</td>
    </tr>
    <tr>
      <th>21</th>
      <td>6867 granville drive</td>
      <td>6867 granville drive</td>
      <td>0</td>
    </tr>
    <tr>
      <th>22</th>
      <td>1600 fire water</td>
      <td>1600 willia ster</td>
      <td>7</td>
    </tr>
    <tr>
      <th>23</th>
      <td>+45-39-007-1887</td>
      <td>+45-39-07-188787</td>
      <td>3</td>
    </tr>
    <tr>
      <th>24</th>
      <td>65634/tennessee%20river</td>
      <td>65634/tenesseeo 2000-rive</td>
      <td>7</td>
    </tr>
    <tr>
      <th>25</th>
      <td>596-033-4046</td>
      <td>515-000-4848</td>
      <td>6</td>
    </tr>
    <tr>
      <th>26</th>
      <td>18 cutter ridge road</td>
      <td>18 cutter ridge road</td>
      <td>0</td>
    </tr>
    <tr>
      <th>27</th>
      <td>tampa fl</td>
      <td>tampa fl</td>
      <td>0</td>
    </tr>
    <tr>
      <th>28</th>
      <td>492288 west 28th terrace south</td>
      <td>492288 west 28th terrace south</td>
      <td>0</td>
    </tr>
    <tr>
      <th>29</th>
      <td>166 water power</td>
      <td>www.santow.com/tarticles</td>
      <td>20</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell code" data-execution_count="55" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T15:01:50.225224Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T15:01:50.224844Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T15:01:50.888066Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T15:01:50.886982Z&quot;}" data-papermill="{&quot;duration&quot;:0.724484,&quot;end_time&quot;:&quot;2023-07-02T15:01:50.890212&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T15:01:50.165728&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb78"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Value Counts</span></span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>LD_TRAIN_VC <span class="op">=</span> <span class="bu">dict</span>([(i, <span class="dv">0</span>) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(LD_TRAIN_DF[<span class="st">&#39;levenshtein_distance&#39;</span>].<span class="bu">max</span>()<span class="op">+</span><span class="dv">1</span>)])</span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ld <span class="kw">in</span> LD_TRAIN_DF[<span class="st">&#39;levenshtein_distance&#39;</span>]:</span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a>    LD_TRAIN_VC[ld] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb78-5"><a href="#cb78-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-6"><a href="#cb78-6" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>,<span class="dv">8</span>))</span>
<span id="cb78-7"><a href="#cb78-7" aria-hidden="true" tabindex="-1"></a>pd.Series(LD_TRAIN_VC).plot(kind<span class="op">=</span><span class="st">&#39;bar&#39;</span>, width<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb78-8"><a href="#cb78-8" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f&#39;Train Levenstein Distance Distribution | Mean: </span><span class="sc">{</span>LD_TRAIN_DF<span class="sc">.</span>levenshtein_distance<span class="sc">.</span>mean()<span class="sc">:.4f}</span><span class="ss">&#39;</span>)</span>
<span id="cb78-9"><a href="#cb78-9" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Levenstein Distance&#39;</span>)</span>
<span id="cb78-10"><a href="#cb78-10" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Sample Count&#39;</span>)</span>
<span id="cb78-11"><a href="#cb78-11" aria-hidden="true" tabindex="-1"></a>plt.xlim(<span class="op">-</span><span class="fl">0.50</span>, LD_TRAIN_DF.levenshtein_distance.<span class="bu">max</span>()<span class="op">+</span><span class="fl">0.50</span>)</span>
<span id="cb78-12"><a href="#cb78-12" aria-hidden="true" tabindex="-1"></a>plt.grid(axis<span class="op">=</span><span class="st">&#39;y&#39;</span>)</span>
<span id="cb78-13"><a href="#cb78-13" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;temp.png&#39;</span>)</span>
<span id="cb78-14"><a href="#cb78-14" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img src="53387b750f55eaf1a268bd32f4ead5acc210a29a.png" /></p>
</div>
</div>
<section id="levenstein-distance-evaluation" class="cell markdown" data-papermill="{&quot;duration&quot;:5.7603e-2,&quot;end_time&quot;:&quot;2023-07-02T15:01:51.005493&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T15:01:50.947890&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Levenstein Distance Evaluation</h1>
</section>
<div class="cell code" data-execution_count="56" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T15:01:51.122346Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T15:01:51.121350Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T15:01:51.129211Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T15:01:51.128227Z&quot;}" data-papermill="{&quot;duration&quot;:6.8889e-2,&quot;end_time&quot;:&quot;2023-07-02T15:01:51.131182&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T15:01:51.062293&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb79"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute Levenstein Distances</span></span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_ld_val():</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a>    N <span class="op">=</span> <span class="dv">100</span> <span class="cf">if</span> IS_INTERACTIVE <span class="cf">else</span> <span class="dv">1000</span></span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a>    LD_VAL <span class="op">=</span> []</span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx, (frames, phrase_true) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">zip</span>(tqdm(X_val, total<span class="op">=</span>N), y_val)):</span>
<span id="cb79-6"><a href="#cb79-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Predict Phrase and Convert to String</span></span>
<span id="cb79-7"><a href="#cb79-7" aria-hidden="true" tabindex="-1"></a>        phrase_pred <span class="op">=</span> predict_phrase(frames).numpy()</span>
<span id="cb79-8"><a href="#cb79-8" aria-hidden="true" tabindex="-1"></a>        phrase_pred <span class="op">=</span> outputs2phrase(phrase_pred)</span>
<span id="cb79-9"><a href="#cb79-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># True Phrase Ordinal to String</span></span>
<span id="cb79-10"><a href="#cb79-10" aria-hidden="true" tabindex="-1"></a>        phrase_true <span class="op">=</span> outputs2phrase(phrase_true)</span>
<span id="cb79-11"><a href="#cb79-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add Levenstein Distance</span></span>
<span id="cb79-12"><a href="#cb79-12" aria-hidden="true" tabindex="-1"></a>        LD_VAL.append({</span>
<span id="cb79-13"><a href="#cb79-13" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;phrase_true&#39;</span>: phrase_true,</span>
<span id="cb79-14"><a href="#cb79-14" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;phrase_pred&#39;</span>: phrase_pred,</span>
<span id="cb79-15"><a href="#cb79-15" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;levenshtein_distance&#39;</span>: levenshtein(phrase_pred, phrase_true),</span>
<span id="cb79-16"><a href="#cb79-16" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb79-17"><a href="#cb79-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Take subset in interactive mode</span></span>
<span id="cb79-18"><a href="#cb79-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idx <span class="op">==</span> N:</span>
<span id="cb79-19"><a href="#cb79-19" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb79-20"><a href="#cb79-20" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb79-21"><a href="#cb79-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert to DataFrame</span></span>
<span id="cb79-22"><a href="#cb79-22" aria-hidden="true" tabindex="-1"></a>    LD_VAL_DF <span class="op">=</span> pd.DataFrame(LD_VAL)</span>
<span id="cb79-23"><a href="#cb79-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb79-24"><a href="#cb79-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> LD_VAL_DF</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="57" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T15:01:51.247268Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T15:01:51.246889Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T15:01:51.251853Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T15:01:51.250791Z&quot;}" data-papermill="{&quot;duration&quot;:6.4943e-2,&quot;end_time&quot;:&quot;2023-07-02T15:01:51.253910&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T15:01:51.188967&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb80"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> USE_VAL:</span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>    LD_VAL_DF <span class="op">=</span> get_ld_val()</span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-4"><a href="#cb80-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Display Errors</span></span>
<span id="cb80-5"><a href="#cb80-5" aria-hidden="true" tabindex="-1"></a>    display(LD_VAL_DF.head(<span class="dv">30</span>))</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="58" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T15:01:51.370726Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T15:01:51.370387Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T15:01:51.377377Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T15:01:51.376450Z&quot;}" data-papermill="{&quot;duration&quot;:6.8365e-2,&quot;end_time&quot;:&quot;2023-07-02T15:01:51.379464&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T15:01:51.311099&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb81"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Value Counts</span></span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> USE_VAL:</span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a>    LD_VAL_VC <span class="op">=</span> <span class="bu">dict</span>([(i, <span class="dv">0</span>) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(LD_VAL_DF[<span class="st">&#39;levenshtein_distance&#39;</span>].<span class="bu">max</span>()<span class="op">+</span><span class="dv">1</span>)])</span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> ld <span class="kw">in</span> LD_VAL_DF[<span class="st">&#39;levenshtein_distance&#39;</span>]:</span>
<span id="cb81-5"><a href="#cb81-5" aria-hidden="true" tabindex="-1"></a>        LD_VAL_VC[ld] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb81-6"><a href="#cb81-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-7"><a href="#cb81-7" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>,<span class="dv">8</span>))</span>
<span id="cb81-8"><a href="#cb81-8" aria-hidden="true" tabindex="-1"></a>    pd.Series(LD_VAL_VC).plot(kind<span class="op">=</span><span class="st">&#39;bar&#39;</span>, width<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb81-9"><a href="#cb81-9" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f&#39;Validation Levenstein Distance Distribution | Mean: </span><span class="sc">{</span>LD_VAL_DF<span class="sc">.</span>levenshtein_distance<span class="sc">.</span>mean()<span class="sc">:.4f}</span><span class="ss">&#39;</span>)</span>
<span id="cb81-10"><a href="#cb81-10" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">&#39;Levenstein Distance&#39;</span>)</span>
<span id="cb81-11"><a href="#cb81-11" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">&#39;Sample Count&#39;</span>)</span>
<span id="cb81-12"><a href="#cb81-12" aria-hidden="true" tabindex="-1"></a>    plt.xlim(<span class="dv">0</span><span class="op">-</span><span class="fl">0.50</span>, LD_VAL_DF.levenshtein_distance.<span class="bu">max</span>()<span class="op">+</span><span class="fl">0.50</span>)</span>
<span id="cb81-13"><a href="#cb81-13" aria-hidden="true" tabindex="-1"></a>    plt.grid(axis<span class="op">=</span><span class="st">&#39;y&#39;</span>)</span>
<span id="cb81-14"><a href="#cb81-14" aria-hidden="true" tabindex="-1"></a>    plt.savefig(<span class="st">&#39;temp.png&#39;</span>)</span>
<span id="cb81-15"><a href="#cb81-15" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code></pre></div>
</div>
<section id="training-history" class="cell markdown" data-papermill="{&quot;duration&quot;:5.6463e-2,&quot;end_time&quot;:&quot;2023-07-02T15:01:51.492470&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T15:01:51.436007&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Training History</h1>
</section>
<div class="cell code" data-execution_count="59" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T15:01:51.607681Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T15:01:51.607331Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T15:01:51.619756Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T15:01:51.618787Z&quot;}" data-papermill="{&quot;duration&quot;:7.2449e-2,&quot;end_time&quot;:&quot;2023-07-02T15:01:51.621731&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T15:01:51.549282&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb82"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_history_metric(metric, f_best<span class="op">=</span>np.argmax, ylim<span class="op">=</span><span class="va">None</span>, yscale<span class="op">=</span><span class="va">None</span>, yticks<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Only plot when training</span></span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> TRAIN_MODEL:</span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span></span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb82-6"><a href="#cb82-6" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">10</span>))</span>
<span id="cb82-7"><a href="#cb82-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb82-8"><a href="#cb82-8" aria-hidden="true" tabindex="-1"></a>    values <span class="op">=</span> history.history[metric]</span>
<span id="cb82-9"><a href="#cb82-9" aria-hidden="true" tabindex="-1"></a>    N_EPOCHS <span class="op">=</span> <span class="bu">len</span>(values)</span>
<span id="cb82-10"><a href="#cb82-10" aria-hidden="true" tabindex="-1"></a>    val <span class="op">=</span> <span class="st">&#39;val&#39;</span> <span class="kw">in</span> <span class="st">&#39;&#39;</span>.join(history.history.keys())</span>
<span id="cb82-11"><a href="#cb82-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Epoch Ticks</span></span>
<span id="cb82-12"><a href="#cb82-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> N_EPOCHS <span class="op">&lt;=</span> <span class="dv">20</span>:</span>
<span id="cb82-13"><a href="#cb82-13" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> np.arange(<span class="dv">1</span>, N_EPOCHS <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb82-14"><a href="#cb82-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb82-15"><a href="#cb82-15" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">5</span>] <span class="op">+</span> [<span class="dv">10</span> <span class="op">+</span> <span class="dv">5</span> <span class="op">*</span> idx <span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>((N_EPOCHS <span class="op">-</span> <span class="dv">10</span>) <span class="op">//</span> <span class="dv">5</span> <span class="op">+</span> <span class="dv">1</span>)]</span>
<span id="cb82-16"><a href="#cb82-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-17"><a href="#cb82-17" aria-hidden="true" tabindex="-1"></a>    x_ticks <span class="op">=</span> np.arange(<span class="dv">1</span>, N_EPOCHS<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb82-18"><a href="#cb82-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-19"><a href="#cb82-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Validation</span></span>
<span id="cb82-20"><a href="#cb82-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> val:</span>
<span id="cb82-21"><a href="#cb82-21" aria-hidden="true" tabindex="-1"></a>        val_values <span class="op">=</span> history.history[<span class="ss">f&#39;val_</span><span class="sc">{</span>metric<span class="sc">}</span><span class="ss">&#39;</span>]</span>
<span id="cb82-22"><a href="#cb82-22" aria-hidden="true" tabindex="-1"></a>        val_argmin <span class="op">=</span> f_best(val_values)</span>
<span id="cb82-23"><a href="#cb82-23" aria-hidden="true" tabindex="-1"></a>        plt.plot(x_ticks, val_values, label<span class="op">=</span><span class="ss">f&#39;val&#39;</span>)</span>
<span id="cb82-24"><a href="#cb82-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-25"><a href="#cb82-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># summarize history for accuracy</span></span>
<span id="cb82-26"><a href="#cb82-26" aria-hidden="true" tabindex="-1"></a>    plt.plot(x_ticks, values, label<span class="op">=</span><span class="ss">f&#39;train&#39;</span>)</span>
<span id="cb82-27"><a href="#cb82-27" aria-hidden="true" tabindex="-1"></a>    argmin <span class="op">=</span> f_best(values)</span>
<span id="cb82-28"><a href="#cb82-28" aria-hidden="true" tabindex="-1"></a>    plt.scatter(argmin <span class="op">+</span> <span class="dv">1</span>, values[argmin], color<span class="op">=</span><span class="st">&#39;red&#39;</span>, s<span class="op">=</span><span class="dv">75</span>, marker<span class="op">=</span><span class="st">&#39;o&#39;</span>, label<span class="op">=</span><span class="ss">f&#39;train_best&#39;</span>)</span>
<span id="cb82-29"><a href="#cb82-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> val:</span>
<span id="cb82-30"><a href="#cb82-30" aria-hidden="true" tabindex="-1"></a>        plt.scatter(val_argmin <span class="op">+</span> <span class="dv">1</span>, val_values[val_argmin], color<span class="op">=</span><span class="st">&#39;purple&#39;</span>, s<span class="op">=</span><span class="dv">75</span>, marker<span class="op">=</span><span class="st">&#39;o&#39;</span>, label<span class="op">=</span><span class="ss">f&#39;val_best&#39;</span>)</span>
<span id="cb82-31"><a href="#cb82-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-32"><a href="#cb82-32" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f&#39;Model </span><span class="sc">{</span>metric<span class="sc">}</span><span class="ss">&#39;</span>, fontsize<span class="op">=</span><span class="dv">24</span>, pad<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb82-33"><a href="#cb82-33" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(metric, fontsize<span class="op">=</span><span class="dv">20</span>, labelpad<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb82-34"><a href="#cb82-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-35"><a href="#cb82-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> ylim:</span>
<span id="cb82-36"><a href="#cb82-36" aria-hidden="true" tabindex="-1"></a>        plt.ylim(ylim)</span>
<span id="cb82-37"><a href="#cb82-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-38"><a href="#cb82-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> yscale <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb82-39"><a href="#cb82-39" aria-hidden="true" tabindex="-1"></a>        plt.yscale(yscale)</span>
<span id="cb82-40"><a href="#cb82-40" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb82-41"><a href="#cb82-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> yticks <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb82-42"><a href="#cb82-42" aria-hidden="true" tabindex="-1"></a>        plt.yticks(yticks, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb82-43"><a href="#cb82-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-44"><a href="#cb82-44" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">&#39;epoch&#39;</span>, fontsize<span class="op">=</span><span class="dv">20</span>, labelpad<span class="op">=</span><span class="dv">10</span>)        </span>
<span id="cb82-45"><a href="#cb82-45" aria-hidden="true" tabindex="-1"></a>    plt.tick_params(axis<span class="op">=</span><span class="st">&#39;x&#39;</span>, labelsize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb82-46"><a href="#cb82-46" aria-hidden="true" tabindex="-1"></a>    plt.xticks(x, fontsize<span class="op">=</span><span class="dv">16</span>) <span class="co"># set tick step to 1 and let x axis start at 1</span></span>
<span id="cb82-47"><a href="#cb82-47" aria-hidden="true" tabindex="-1"></a>    plt.yticks(fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb82-48"><a href="#cb82-48" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb82-49"><a href="#cb82-49" aria-hidden="true" tabindex="-1"></a>    plt.legend(prop<span class="op">=</span>{<span class="st">&#39;size&#39;</span>: <span class="dv">10</span>})</span>
<span id="cb82-50"><a href="#cb82-50" aria-hidden="true" tabindex="-1"></a>    plt.grid()</span>
<span id="cb82-51"><a href="#cb82-51" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="60" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T15:01:51.738312Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T15:01:51.737734Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T15:01:52.210950Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T15:01:52.209998Z&quot;}" data-papermill="{&quot;duration&quot;:0.534279,&quot;end_time&quot;:&quot;2023-07-02T15:01:52.213146&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T15:01:51.678867&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb83"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>plot_history_metric(<span class="st">&#39;loss&#39;</span>, f_best<span class="op">=</span>np.argmin)</span></code></pre></div>
<div class="output display_data">
<p><img src="159e738883f5dd9f3dc4638e2b661a683d0f2492.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="61" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T15:01:52.330465Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T15:01:52.330112Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T15:01:52.811024Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T15:01:52.810096Z&quot;}" data-papermill="{&quot;duration&quot;:0.542072,&quot;end_time&quot;:&quot;2023-07-02T15:01:52.812958&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T15:01:52.270886&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb84"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>plot_history_metric(<span class="st">&#39;top1acc&#39;</span>, ylim<span class="op">=</span>[<span class="dv">0</span>,<span class="dv">1</span>], yticks<span class="op">=</span>np.arange(<span class="fl">0.0</span>, <span class="fl">1.1</span>, <span class="fl">0.1</span>))</span></code></pre></div>
<div class="output display_data">
<p><img src="3b19b7dc467d02e2bcb090ff521cfd58818586a2.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="62" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T15:01:52.936426Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T15:01:52.936030Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T15:01:53.414640Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T15:01:53.413713Z&quot;}" data-papermill="{&quot;duration&quot;:0.542339,&quot;end_time&quot;:&quot;2023-07-02T15:01:53.417063&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T15:01:52.874724&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb85"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>plot_history_metric(<span class="st">&#39;top5acc&#39;</span>, ylim<span class="op">=</span>[<span class="dv">0</span>,<span class="dv">1</span>], yticks<span class="op">=</span>np.arange(<span class="fl">0.0</span>, <span class="fl">1.1</span>, <span class="fl">0.1</span>))</span></code></pre></div>
<div class="output display_data">
<p><img src="b7b2a45070b58844ed55f9057a1bc2c58641cf7a.png" /></p>
</div>
</div>
<section id="inference" class="cell markdown" data-papermill="{&quot;duration&quot;:5.9194e-2,&quot;end_time&quot;:&quot;2023-07-02T15:01:53.537697&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T15:01:53.478503&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<h1>Inference</h1>
</section>
<div class="cell code" data-execution_count="63" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T15:01:53.658590Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T15:01:53.658218Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T15:01:53.665909Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T15:01:53.665058Z&quot;}" data-papermill="{&quot;duration&quot;:7.0811e-2,&quot;end_time&quot;:&quot;2023-07-02T15:01:53.667988&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T15:01:53.597177&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb86"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Model Layer Names</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> l <span class="kw">in</span> model.layers:</span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(l.name)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>frames
masking
embedding
encoder
phrase
decoder
classifier
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="64" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T15:01:53.789495Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T15:01:53.789149Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T15:02:00.232802Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T15:02:00.231814Z&quot;}" data-papermill="{&quot;duration&quot;:6.507954,&quot;end_time&quot;:&quot;2023-07-02T15:02:00.234987&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T15:01:53.727033&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb88"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="co"># TFLite model for submission</span></span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TFLiteModel(tf.Module):</span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, model):</span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(TFLiteModel, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb88-5"><a href="#cb88-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-6"><a href="#cb88-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Load the feature generation and main models</span></span>
<span id="cb88-7"><a href="#cb88-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.preprocess_layer <span class="op">=</span> preprocess_layer</span>
<span id="cb88-8"><a href="#cb88-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> model</span>
<span id="cb88-9"><a href="#cb88-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb88-10"><a href="#cb88-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">@tf.function</span>(jit_compile<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb88-11"><a href="#cb88-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> encoder(<span class="va">self</span>, x, frames_inp):</span>
<span id="cb88-12"><a href="#cb88-12" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.model.get_layer(<span class="st">&#39;embedding&#39;</span>)(x)</span>
<span id="cb88-13"><a href="#cb88-13" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.model.get_layer(<span class="st">&#39;encoder&#39;</span>)(x, frames_inp)</span>
<span id="cb88-14"><a href="#cb88-14" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb88-15"><a href="#cb88-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb88-16"><a href="#cb88-16" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb88-17"><a href="#cb88-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">@tf.function</span>(jit_compile<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb88-18"><a href="#cb88-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> decoder(<span class="va">self</span>, x, phrase_inp):</span>
<span id="cb88-19"><a href="#cb88-19" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.model.get_layer(<span class="st">&#39;decoder&#39;</span>)(x, phrase_inp)</span>
<span id="cb88-20"><a href="#cb88-20" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.model.get_layer(<span class="st">&#39;classifier&#39;</span>)(x)</span>
<span id="cb88-21"><a href="#cb88-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb88-22"><a href="#cb88-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb88-23"><a href="#cb88-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb88-24"><a href="#cb88-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">@tf.function</span>(input_signature<span class="op">=</span>[tf.TensorSpec(shape<span class="op">=</span>[<span class="va">None</span>, N_COLS0], dtype<span class="op">=</span>tf.float32, name<span class="op">=</span><span class="st">&#39;inputs&#39;</span>)])</span>
<span id="cb88-25"><a href="#cb88-25" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, inputs):</span>
<span id="cb88-26"><a href="#cb88-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Number Of Input Frames</span></span>
<span id="cb88-27"><a href="#cb88-27" aria-hidden="true" tabindex="-1"></a>        N_INPUT_FRAMES <span class="op">=</span> tf.shape(inputs)[<span class="dv">0</span>]</span>
<span id="cb88-28"><a href="#cb88-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Preprocess Data</span></span>
<span id="cb88-29"><a href="#cb88-29" aria-hidden="true" tabindex="-1"></a>        frames_inp <span class="op">=</span> <span class="va">self</span>.preprocess_layer(inputs)        </span>
<span id="cb88-30"><a href="#cb88-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add Batch Dimension</span></span>
<span id="cb88-31"><a href="#cb88-31" aria-hidden="true" tabindex="-1"></a>        frames_inp <span class="op">=</span> tf.expand_dims(frames_inp, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb88-32"><a href="#cb88-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get Encoding</span></span>
<span id="cb88-33"><a href="#cb88-33" aria-hidden="true" tabindex="-1"></a>        encoding <span class="op">=</span> <span class="va">self</span>.encoder(frames_inp, frames_inp)</span>
<span id="cb88-34"><a href="#cb88-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Make Prediction</span></span>
<span id="cb88-35"><a href="#cb88-35" aria-hidden="true" tabindex="-1"></a>        phrase <span class="op">=</span> tf.fill([<span class="dv">1</span>,MAX_PHRASE_LENGTH], PAD_TOKEN)</span>
<span id="cb88-36"><a href="#cb88-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Predict One Token At A Time</span></span>
<span id="cb88-37"><a href="#cb88-37" aria-hidden="true" tabindex="-1"></a>        stop <span class="op">=</span> <span class="va">False</span></span>
<span id="cb88-38"><a href="#cb88-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> idx <span class="kw">in</span> tf.<span class="bu">range</span>(MAX_PHRASE_LENGTH):</span>
<span id="cb88-39"><a href="#cb88-39" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Cast phrase to int8</span></span>
<span id="cb88-40"><a href="#cb88-40" aria-hidden="true" tabindex="-1"></a>            phrase <span class="op">=</span> tf.cast(phrase, tf.int8)</span>
<span id="cb88-41"><a href="#cb88-41" aria-hidden="true" tabindex="-1"></a>            <span class="co"># If EOS token is predicted, stop predicting</span></span>
<span id="cb88-42"><a href="#cb88-42" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> tf.cond(</span>
<span id="cb88-43"><a href="#cb88-43" aria-hidden="true" tabindex="-1"></a>                stop,</span>
<span id="cb88-44"><a href="#cb88-44" aria-hidden="true" tabindex="-1"></a>                <span class="kw">lambda</span>: tf.one_hot(tf.cast(phrase, tf.int32), N_UNIQUE_CHARACTERS),</span>
<span id="cb88-45"><a href="#cb88-45" aria-hidden="true" tabindex="-1"></a>                <span class="kw">lambda</span>: <span class="va">self</span>.decoder(encoding, phrase)</span>
<span id="cb88-46"><a href="#cb88-46" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb88-47"><a href="#cb88-47" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Add predicted token to input phrase</span></span>
<span id="cb88-48"><a href="#cb88-48" aria-hidden="true" tabindex="-1"></a>            phrase <span class="op">=</span> tf.cast(phrase, tf.int32)</span>
<span id="cb88-49"><a href="#cb88-49" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Replcae PAD token with predicted token up to idx</span></span>
<span id="cb88-50"><a href="#cb88-50" aria-hidden="true" tabindex="-1"></a>            phrase <span class="op">=</span> tf.where(</span>
<span id="cb88-51"><a href="#cb88-51" aria-hidden="true" tabindex="-1"></a>                tf.<span class="bu">range</span>(MAX_PHRASE_LENGTH) <span class="op">&lt;</span> idx <span class="op">+</span> <span class="dv">1</span>,</span>
<span id="cb88-52"><a href="#cb88-52" aria-hidden="true" tabindex="-1"></a>                tf.argmax(outputs, axis<span class="op">=</span><span class="dv">2</span>, output_type<span class="op">=</span>tf.int32),</span>
<span id="cb88-53"><a href="#cb88-53" aria-hidden="true" tabindex="-1"></a>                phrase,</span>
<span id="cb88-54"><a href="#cb88-54" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb88-55"><a href="#cb88-55" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Predicted Token</span></span>
<span id="cb88-56"><a href="#cb88-56" aria-hidden="true" tabindex="-1"></a>            predicted_token <span class="op">=</span> phrase[<span class="dv">0</span>,idx]</span>
<span id="cb88-57"><a href="#cb88-57" aria-hidden="true" tabindex="-1"></a>            <span class="co"># If EOS (End Of Sentence) token is predicted stop</span></span>
<span id="cb88-58"><a href="#cb88-58" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="kw">not</span> stop:</span>
<span id="cb88-59"><a href="#cb88-59" aria-hidden="true" tabindex="-1"></a>                stop <span class="op">=</span> predicted_token <span class="op">==</span> EOS_TOKEN</span>
<span id="cb88-60"><a href="#cb88-60" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb88-61"><a href="#cb88-61" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Squeeze outputs</span></span>
<span id="cb88-62"><a href="#cb88-62" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> tf.squeeze(phrase, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb88-63"><a href="#cb88-63" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> tf.one_hot(outputs, N_UNIQUE_CHARACTERS)</span>
<span id="cb88-64"><a href="#cb88-64" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb88-65"><a href="#cb88-65" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Return a dictionary with the output tensor</span></span>
<span id="cb88-66"><a href="#cb88-66" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {<span class="st">&#39;outputs&#39;</span>: outputs }</span>
<span id="cb88-67"><a href="#cb88-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-68"><a href="#cb88-68" aria-hidden="true" tabindex="-1"></a><span class="co"># Define TF Lite Model</span></span>
<span id="cb88-69"><a href="#cb88-69" aria-hidden="true" tabindex="-1"></a>tflite_keras_model <span class="op">=</span> TFLiteModel(model)</span>
<span id="cb88-70"><a href="#cb88-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-71"><a href="#cb88-71" aria-hidden="true" tabindex="-1"></a><span class="co"># Sanity Check</span></span>
<span id="cb88-72"><a href="#cb88-72" aria-hidden="true" tabindex="-1"></a><span class="co"># demo_sequence_id = 1816796431</span></span>
<span id="cb88-73"><a href="#cb88-73" aria-hidden="true" tabindex="-1"></a>demo_sequence_id <span class="op">=</span> example_parquet_df.index.unique()[<span class="dv">0</span>]</span>
<span id="cb88-74"><a href="#cb88-74" aria-hidden="true" tabindex="-1"></a>demo_raw_data <span class="op">=</span> example_parquet_df.loc[demo_sequence_id, COLUMNS0].values</span>
<span id="cb88-75"><a href="#cb88-75" aria-hidden="true" tabindex="-1"></a>demo_phrase_true <span class="op">=</span> train_sequence_id.loc[demo_sequence_id, <span class="st">&#39;phrase&#39;</span>]</span>
<span id="cb88-76"><a href="#cb88-76" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;demo_raw_data shape: </span><span class="sc">{</span>demo_raw_data<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, dtype: </span><span class="sc">{</span>demo_raw_data<span class="sc">.</span>dtype<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb88-77"><a href="#cb88-77" aria-hidden="true" tabindex="-1"></a>demo_output <span class="op">=</span> tflite_keras_model(demo_raw_data)[<span class="st">&#39;outputs&#39;</span>].numpy()</span>
<span id="cb88-78"><a href="#cb88-78" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;demo_output shape: </span><span class="sc">{</span>demo_output<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, dtype: </span><span class="sc">{</span>demo_output<span class="sc">.</span>dtype<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb88-79"><a href="#cb88-79" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;demo_outputs phrase decoded: </span><span class="sc">{</span>outputs2phrase(demo_output)<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb88-80"><a href="#cb88-80" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;phrase true: </span><span class="sc">{</span>demo_phrase_true<span class="sc">}</span><span class="ss">&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>demo_raw_data shape: (123, 164), dtype: float32
demo_output shape: (32, 62), dtype: float32
demo_outputs phrase decoded: 3 creek house
phrase true: 3 creekhouse
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="65" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T15:02:00.356778Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T15:02:00.356421Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T15:03:03.579772Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T15:03:03.578707Z&quot;}" data-papermill="{&quot;duration&quot;:63.286967,&quot;end_time&quot;:&quot;2023-07-02T15:03:03.582231&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T15:02:00.295264&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb90"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create Model Converter</span></span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>keras_model_converter <span class="op">=</span> tf.lite.TFLiteConverter.from_keras_model(tflite_keras_model)</span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert Model</span></span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a>tflite_model <span class="op">=</span> keras_model_converter.convert()</span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Write Model</span></span>
<span id="cb90-6"><a href="#cb90-6" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">&#39;/kaggle/working/model.tflite&#39;</span>, <span class="st">&#39;wb&#39;</span>) <span class="im">as</span> f:</span>
<span id="cb90-7"><a href="#cb90-7" aria-hidden="true" tabindex="-1"></a>    f.write(tflite_model)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="66" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T15:03:03.705891Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T15:03:03.705540Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T15:03:03.711677Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T15:03:03.711031Z&quot;}" data-papermill="{&quot;duration&quot;:7.0965e-2,&quot;end_time&quot;:&quot;2023-07-02T15:03:03.713519&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T15:03:03.642554&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb91"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Add selected_columns json to only select specific columns from input frames</span></span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">&#39;inference_args.json&#39;</span>, <span class="st">&#39;w&#39;</span>) <span class="im">as</span> f:</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>     json.dump({ <span class="st">&#39;selected_columns&#39;</span>: COLUMNS0.tolist() }, f)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="67" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-07-02T15:03:03.835271Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-07-02T15:03:03.834244Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-07-02T15:03:05.697681Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-07-02T15:03:05.695879Z&quot;}" data-papermill="{&quot;duration&quot;:1.931415,&quot;end_time&quot;:&quot;2023-07-02T15:03:05.704490&quot;,&quot;exception&quot;:false,&quot;start_time&quot;:&quot;2023-07-02T15:03:03.773075&quot;,&quot;status&quot;:&quot;completed&quot;}" data-tags="[]">
<div class="sourceCode" id="cb92"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Zip Model</span></span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span><span class="bu">zip</span> submission.<span class="bu">zip</span> <span class="op">/</span>kaggle<span class="op">/</span>working<span class="op">/</span>model.tflite <span class="op">/</span>kaggle<span class="op">/</span>working<span class="op">/</span>inference_args.json</span></code></pre></div>
<div class="output stream stdout">
<pre><code>  adding: kaggle/working/model.tflite (deflated 9%)
  adding: kaggle/working/inference_args.json (deflated 83%)
</code></pre>
</div>
</div>
</body>
</html>
